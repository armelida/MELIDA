{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVKWiiDoleq0u1uB6UP2ZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armelida/MELIDA/blob/main/src/questions-scraper/MELIDA_PDF_Scraper_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2YwGaUcetnwH"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install pdfplumber pandas --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pdfplumber pandas --quiet"
      ],
      "metadata": {
        "id": "o6bR_lp8t-_j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown for Google Drive access\n",
        "!pip install gdown --quiet\n",
        "\n",
        "# Configure paths\n",
        "import os\n",
        "\n",
        "# Use a local directory structure in Colab instead of MyDrive\n",
        "BASE_PATH = \"/content/MELIDA\"  # Changed from MyDrive path\n",
        "PDF_DIR = os.path.join(BASE_PATH, \"data/raw/exams\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"data/questions\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"PDF Directory: {PDF_DIR}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# Download files from the shared Google Drive folder\n",
        "folder_id = \"1QXwB1AXaV8TlgqoN41PIdwn1VSDJI1zg\"\n",
        "print(f\"Downloading PDFs from Google Drive folder ID: {folder_id}\")\n",
        "\n",
        "# List and download files from the shared folder\n",
        "!gdown --folder --id {folder_id} -O {PDF_DIR}\n",
        "\n",
        "# List downloaded PDFs\n",
        "pdf_files = [f for f in os.listdir(PDF_DIR) if f.lower().endswith('.pdf')]\n",
        "print(f\"\\nFound {len(pdf_files)} PDF files in {PDF_DIR}:\")\n",
        "for i, file in enumerate(pdf_files, 1):\n",
        "    print(f\"{i}. {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ps_aBquEIu",
        "outputId": "acc0cd21-6262-4178-b767-b10352f89539"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Directory: /content/MELIDA/data/raw/exams\n",
            "Output Directory: /content/MELIDA/data/questions\n",
            "Downloading PDFs from Google Drive folder ID: 1QXwB1AXaV8TlgqoN41PIdwn1VSDJI1zg\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Retrieving folder contents\n",
            "Processing file 12-eLFeor5K8RGn8jcIstT-ZvSBLG29SA Cuaderno_2024_MEDICINA_0_C.pdf\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12-eLFeor5K8RGn8jcIstT-ZvSBLG29SA\n",
            "To: /content/MELIDA/data/raw/exams/Cuaderno_2024_MEDICINA_0_C.pdf\n",
            "100% 797k/797k [00:00<00:00, 27.3MB/s]\n",
            "Download completed\n",
            "\n",
            "Found 1 PDF files in /content/MELIDA/data/raw/exams:\n",
            "1. Cuaderno_2024_MEDICINA_0_C.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "def get_exam_metadata(filename: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extracts exam type and year from filename\n",
        "    Example: 'Cuaderno_2024_MEDICINA_0_C.pdf' -> ('MIR', '2024')\n",
        "    Adjust patterns as needed for different exam types\n",
        "    \"\"\"\n",
        "    # Default values\n",
        "    exam_type = \"MIR\"\n",
        "    year = \"UNKNOWN\"\n",
        "\n",
        "    # Extract year\n",
        "    year_match = re.search(r'(\\d{4})', filename)\n",
        "    if year_match:\n",
        "        year = year_match.group(1)\n",
        "\n",
        "    # Extract exam type if present (customize based on your naming conventions)\n",
        "    if \"MEDICINA\" in filename.upper():\n",
        "        exam_type = \"MIR\"\n",
        "    elif \"ENFERMERIA\" in filename.upper():\n",
        "        exam_type = \"EIR\"\n",
        "    # Add more exam types as needed\n",
        "\n",
        "    return exam_type, year\n",
        "\n",
        "\n",
        "def format_question_id(exam_type: str, year: str, version: str = \"v01\",\n",
        "                       question_type: str = \"t01\", question_num: int = 0) -> str:\n",
        "    \"\"\"\n",
        "    Creates standardized question ID\n",
        "    Format: {exam_type}-{year}-{version}-{question_type}-Q{question_num:03d}\n",
        "    Example: MIR-2024-v01-t01-Q026\n",
        "    \"\"\"\n",
        "    return f\"{exam_type}-{year}-{version}-{question_type}-Q{question_num:03d}\"\n",
        "\n",
        "\n",
        "def create_formatted_question(exam_type: str, year: str, qnum: int,\n",
        "                             qtext: str, options: List[str],\n",
        "                             source_file: str, page_num: int) -> Dict:\n",
        "    \"\"\"\n",
        "    Creates a question dict with the required format\n",
        "    \"\"\"\n",
        "    # Clean the question text\n",
        "    text = re.sub(r'\\s+', ' ', qtext).strip()\n",
        "    text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)  # Merge hyphen-split\n",
        "    text = re.sub(r'\\[(.*?)\\]', r'\\1', text)       # Remove bracket formatting\n",
        "\n",
        "    # Format options as required dictionary with A, B, C, D keys\n",
        "    option_dict = {}\n",
        "    option_keys = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "    for i, opt in enumerate(options):\n",
        "        if i < len(option_keys):\n",
        "            opt = re.sub(r'\\s+', ' ', opt).strip()\n",
        "            option_dict[option_keys[i]] = opt\n",
        "\n",
        "    # Ensure all options exist even if empty\n",
        "    for key in option_keys:\n",
        "        if key not in option_dict:\n",
        "            option_dict[key] = \"\"\n",
        "\n",
        "    # Create the question object in the required format\n",
        "    return {\n",
        "        \"id\": format_question_id(exam_type, year, question_num=qnum),\n",
        "        \"question_text\": text,\n",
        "        \"options\": option_dict,\n",
        "        # Metadata fields (not in final output but useful for debugging)\n",
        "        \"_metadata\": {\n",
        "            \"source_file\": source_file,\n",
        "            \"page_number\": page_num,\n",
        "            \"original_number\": qnum\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_lines_with_x0(page, bbox):\n",
        "    \"\"\"\n",
        "    Crops to bbox, extracts text lines as (text, x0).\n",
        "    Merges lines ending in '-'.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    hyphen_buffer = \"\"\n",
        "\n",
        "    cropped = page.crop(bbox)\n",
        "    raw_lines = cropped.extract_text_lines()\n",
        "\n",
        "    for ln in raw_lines:\n",
        "        text = ln[\"text\"].strip()\n",
        "        x0_val = ln[\"x0\"]\n",
        "\n",
        "        if hyphen_buffer:\n",
        "            text = hyphen_buffer + text\n",
        "            hyphen_buffer = \"\"\n",
        "\n",
        "        if re.search(r'-\\s*$', text):\n",
        "            hyphen_buffer = re.sub(r'-\\s*$', '', text)\n",
        "            continue\n",
        "\n",
        "        lines.append((text, x0_val))\n",
        "    return lines\n",
        "\n",
        "\n",
        "def split_markers(line_text):\n",
        "    \"\"\"\n",
        "    Splits on every '(\\\\d+)\\\\. ' pattern.\n",
        "    Returns [(num_str_or_None, snippet)].\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'(\\d+)\\.\\s')\n",
        "    tokens = pattern.split(line_text)\n",
        "\n",
        "    results = []\n",
        "    leftover = tokens[0].strip()\n",
        "    if leftover:\n",
        "        results.append((None, leftover))\n",
        "\n",
        "    i = 1\n",
        "    while i < len(tokens):\n",
        "        num_str = tokens[i]\n",
        "        i += 1\n",
        "        snippet = tokens[i].strip() if i < len(tokens) else \"\"\n",
        "        i += 1\n",
        "        results.append((num_str, snippet))\n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_lines(\n",
        "    lines, page_idx, exam_type, year, source_file,\n",
        "    questions,\n",
        "    current_qnum, current_qtext, current_opts,\n",
        "    expected_next_qnum=None  # Track expected next question number\n",
        "):\n",
        "    \"\"\"\n",
        "    Enhanced state machine logic to extract questions and options\n",
        "    With validation and warnings instead of automatic placeholders\n",
        "    \"\"\"\n",
        "    MAX_QNUM = 210\n",
        "    parsing_warnings = []\n",
        "\n",
        "    # Initialize expected next question number if not provided\n",
        "    if expected_next_qnum is None and current_qnum is not None:\n",
        "        expected_next_qnum = current_qnum + 1\n",
        "    elif expected_next_qnum is None:\n",
        "        expected_next_qnum = 1\n",
        "\n",
        "    for (full_line, _x0) in lines:\n",
        "        if not full_line.strip():\n",
        "            continue\n",
        "\n",
        "        segments = split_markers(full_line)\n",
        "\n",
        "        for (num_str, snippet) in segments:\n",
        "            snippet = snippet.strip()\n",
        "\n",
        "            if num_str is not None:\n",
        "                val = int(num_str)\n",
        "\n",
        "                # CASE A: Potential option if 1..4\n",
        "                if 1 <= val <= 4:\n",
        "                    # Check if we have a current question\n",
        "                    if current_qnum is not None:\n",
        "                        # If options are not sequential, that's a problem\n",
        "                        if len(current_opts) > 0 and val != len(current_opts) + 1:\n",
        "                            warning = f\"Non-sequential option: Found option {val} after option {len(current_opts)} for question {current_qnum}\"\n",
        "                            parsing_warnings.append(warning)\n",
        "                            print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                            # Possible recovery: check if this actually belongs to the next question\n",
        "                            if val == 1 and not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "                                # This might be the start of next question's text that was incorrectly detected\n",
        "                                # Look for : or ? in this snippet\n",
        "                                colon_pos = snippet.find(':')\n",
        "                                qmark_pos = snippet.find('?')\n",
        "\n",
        "                                if colon_pos >= 0 or qmark_pos >= 0:\n",
        "                                    # This might be a new question starting with option 1 text\n",
        "                                    # Finish current question\n",
        "                                    if len(current_opts) < 4:\n",
        "                                        warning = f\"Incomplete options: Question {current_qnum} has only {len(current_opts)} options (expected 4)\"\n",
        "                                        parsing_warnings.append(warning)\n",
        "                                        print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                                    questions.append(create_formatted_question(\n",
        "                                        exam_type,\n",
        "                                        year,\n",
        "                                        current_qnum,\n",
        "                                        current_qtext,\n",
        "                                        current_opts,\n",
        "                                        source_file,\n",
        "                                        page_idx + 1\n",
        "                                    ))\n",
        "\n",
        "                                    # Start new question with this text\n",
        "                                    current_qnum = expected_next_qnum\n",
        "                                    current_qtext = f\"{val}. {snippet}\"\n",
        "                                    current_opts = []\n",
        "                                    expected_next_qnum += 1\n",
        "                                    continue\n",
        "\n",
        "                            # If we didn't start a new question, append to current content\n",
        "                            if current_opts:\n",
        "                                current_opts[-1] += f\" {val}. {snippet}\"\n",
        "                            else:\n",
        "                                current_qtext += f\" {val}. {snippet}\"\n",
        "                            continue\n",
        "\n",
        "                        # Before adding first option, ensure question ends properly\n",
        "                        if len(current_opts) == 0 and not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "                            # Look for : or ? in the snippet\n",
        "                            colon_pos = snippet.find(':')\n",
        "                            qmark_pos = snippet.find('?')\n",
        "\n",
        "                            if colon_pos >= 0:\n",
        "                                # Split at colon - move text before colon to question\n",
        "                                current_qtext += \" \" + snippet[:colon_pos+1].strip()\n",
        "                                snippet = snippet[colon_pos+1:].strip()\n",
        "                            elif qmark_pos >= 0:\n",
        "                                # Split at question mark - move text before ? to question\n",
        "                                current_qtext += \" \" + snippet[:qmark_pos+1].strip()\n",
        "                                snippet = snippet[qmark_pos+1:].strip()\n",
        "                            else:\n",
        "                                # No ending found, this might actually be part of the question\n",
        "                                warning = f\"Question {current_qnum} has no proper ending before options\"\n",
        "                                parsing_warnings.append(warning)\n",
        "                                print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                        # Add the option\n",
        "                        current_opts.append(snippet)\n",
        "                    else:\n",
        "                        # No active question, but found option number\n",
        "                        warning = f\"Found option {val} with no active question\"\n",
        "                        parsing_warnings.append(warning)\n",
        "                        print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                        # This might actually be a new question\n",
        "                        current_qnum = val\n",
        "                        current_qtext = snippet\n",
        "                        current_opts = []\n",
        "\n",
        "                # CASE B: potential question number (5..210)\n",
        "                else:\n",
        "                    if val <= MAX_QNUM:\n",
        "                        # Check if this matches our expected next question number\n",
        "                        if val != expected_next_qnum and current_qnum is not None:\n",
        "                            # Out of sequence question number detected!\n",
        "                            gap = val - expected_next_qnum\n",
        "\n",
        "                            if gap > 0:\n",
        "                                warning = f\"Question number gap: Expected {expected_next_qnum}, found {val} (gap of {gap})\"\n",
        "                            else:\n",
        "                                warning = f\"Out of order question: Expected {expected_next_qnum}, found {val} (backwards by {-gap})\"\n",
        "\n",
        "                            parsing_warnings.append(warning)\n",
        "                            print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                            if gap > 3 or gap < 0:\n",
        "                                # Large gap or backward numbering - this might not be a question number\n",
        "                                # Treat it as part of current question/option\n",
        "                                if current_opts:\n",
        "                                    current_opts[-1] += f\" {val}. {snippet}\"\n",
        "                                else:\n",
        "                                    current_qtext += f\" {val}. {snippet}\"\n",
        "                                continue\n",
        "\n",
        "                        # Finalize old question if any\n",
        "                        if current_qnum is not None:\n",
        "                            # Check for incomplete options\n",
        "                            if len(current_opts) < 4:\n",
        "                                warning = f\"Incomplete options: Question {current_qnum} has only {len(current_opts)} options (expected 4)\"\n",
        "                                parsing_warnings.append(warning)\n",
        "                                print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                            # Ensure question ends properly before finalizing\n",
        "                            if not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "                                # Try to find ending in the first option if available\n",
        "                                if current_opts:\n",
        "                                    first_opt = current_opts[0]\n",
        "                                    colon_pos = first_opt.find(':')\n",
        "                                    qmark_pos = first_opt.find('?')\n",
        "\n",
        "                                    if colon_pos >= 0:\n",
        "                                        # Move text before colon to question\n",
        "                                        current_qtext += \" \" + first_opt[:colon_pos+1].strip()\n",
        "                                        current_opts[0] = first_opt[colon_pos+1:].strip()\n",
        "                                    elif qmark_pos >= 0:\n",
        "                                        # Move text before question mark to question\n",
        "                                        current_qtext += \" \" + first_opt[:qmark_pos+1].strip()\n",
        "                                        current_opts[0] = first_opt[qmark_pos+1:].strip()\n",
        "\n",
        "                                if not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "                                    warning = f\"Question {current_qnum} has no proper ending\"\n",
        "                                    parsing_warnings.append(warning)\n",
        "                                    print(f\"WARNING: {warning} (page {page_idx+1})\")\n",
        "\n",
        "                            # Now finalize the question with whatever options we found\n",
        "                            questions.append(create_formatted_question(\n",
        "                                exam_type,\n",
        "                                year,\n",
        "                                current_qnum,\n",
        "                                current_qtext,\n",
        "                                current_opts,\n",
        "                                source_file,\n",
        "                                page_idx + 1\n",
        "                            ))\n",
        "\n",
        "                        # Start new question\n",
        "                        current_qnum = val\n",
        "                        current_qtext = snippet\n",
        "                        current_opts = []\n",
        "                        expected_next_qnum = val + 1  # Update expected next number\n",
        "                    else:\n",
        "                        # Number out of range => just leftover text\n",
        "                        if current_opts:\n",
        "                            current_opts[-1] += f\" {val}. {snippet}\"\n",
        "                        elif current_qnum is not None:\n",
        "                            current_qtext += f\" {val}. {snippet}\"\n",
        "\n",
        "            else:\n",
        "                # leftover text without a number prefix\n",
        "                if current_qnum is not None:\n",
        "                    # If we don't have a properly ended question yet and there are no options\n",
        "                    if not (current_qtext.endswith(':') or current_qtext.endswith('?')) and not current_opts:\n",
        "                        # Look for \":\" or \"?\" in the snippet\n",
        "                        colon_pos = snippet.find(':')\n",
        "                        qmark_pos = snippet.find('?')\n",
        "\n",
        "                        if colon_pos >= 0:\n",
        "                            # Split the snippet at the colon\n",
        "                            current_qtext += \" \" + snippet[:colon_pos+1].strip()\n",
        "                            remaining = snippet[colon_pos+1:].strip()\n",
        "                            if remaining:\n",
        "                                # Start first option with remaining text\n",
        "                                current_opts.append(remaining)\n",
        "                            continue\n",
        "                        elif qmark_pos >= 0:\n",
        "                            # Split the snippet at the question mark\n",
        "                            current_qtext += \" \" + snippet[:qmark_pos+1].strip()\n",
        "                            remaining = snippet[qmark_pos+1:].strip()\n",
        "                            if remaining:\n",
        "                                # Start first option with remaining text\n",
        "                                current_opts.append(remaining)\n",
        "                            continue\n",
        "\n",
        "                    # Normal case - append to appropriate place\n",
        "                    if current_opts:\n",
        "                        current_opts[-1] += \" \" + snippet\n",
        "                    else:\n",
        "                        current_qtext += \" \" + snippet\n",
        "                # else we have no active question => ignore\n",
        "\n",
        "    return current_qnum, current_qtext, current_opts, expected_next_qnum, parsing_warnings\n",
        "\n",
        "\n",
        "def process_pdf(pdf_path: str, start_page: int = 2) -> tuple:\n",
        "    \"\"\"\n",
        "    Process PDF and extract questions with options\n",
        "    Returns both questions and warnings about extraction issues\n",
        "    \"\"\"\n",
        "    questions = []\n",
        "    warnings = []\n",
        "    current_qnum = None\n",
        "    current_qtext = \"\"\n",
        "    current_opts = []\n",
        "    expected_next_qnum = 1  # Start expecting question #1\n",
        "\n",
        "    # Extract metadata from filename\n",
        "    filename = os.path.basename(pdf_path)\n",
        "    exam_type, year = get_exam_metadata(filename)\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        source_file = os.path.basename(pdf_path)\n",
        "        num_pages = len(pdf.pages)\n",
        "\n",
        "        for i in range(start_page, num_pages):\n",
        "            page = pdf.pages[i]\n",
        "            w, h = page.width, page.height\n",
        "            mid_x = w / 2.0\n",
        "\n",
        "            # Split page into left and right columns\n",
        "            left_bbox = (0, 0, mid_x, h)\n",
        "            right_bbox = (mid_x, 0, w, h)\n",
        "\n",
        "            left_lines = extract_lines_with_x0(page, left_bbox)\n",
        "            right_lines = extract_lines_with_x0(page, right_bbox)\n",
        "\n",
        "            # Parse left column\n",
        "            current_qnum, current_qtext, current_opts, expected_next_qnum, page_warnings = parse_lines(\n",
        "                left_lines, i, exam_type, year, source_file,\n",
        "                questions,\n",
        "                current_qnum, current_qtext, current_opts, expected_next_qnum\n",
        "            )\n",
        "            warnings.extend(page_warnings)\n",
        "\n",
        "            # Parse right column\n",
        "            current_qnum, current_qtext, current_opts, expected_next_qnum, page_warnings = parse_lines(\n",
        "                right_lines, i, exam_type, year, source_file,\n",
        "                questions,\n",
        "                current_qnum, current_qtext, current_opts, expected_next_qnum\n",
        "            )\n",
        "            warnings.extend(page_warnings)\n",
        "\n",
        "    # Add the last question if not already added\n",
        "    if current_qnum is not None:\n",
        "        # Check for incomplete options\n",
        "        if len(current_opts) < 4:\n",
        "            warning = f\"Incomplete options: Final question {current_qnum} has only {len(current_opts)} options (expected 4)\"\n",
        "            warnings.append(warning)\n",
        "            print(f\"WARNING: {warning}\")\n",
        "\n",
        "        # Ensure question ends properly before finalizing\n",
        "        if not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "            # Try to find ending in the first option if available\n",
        "            if current_opts:\n",
        "                first_opt = current_opts[0]\n",
        "                colon_pos = first_opt.find(':')\n",
        "                qmark_pos = first_opt.find('?')\n",
        "\n",
        "                if colon_pos >= 0:\n",
        "                    # Move text before colon to question\n",
        "                    current_qtext += \" \" + first_opt[:colon_pos+1].strip()\n",
        "                    current_opts[0] = first_opt[colon_pos+1:].strip()\n",
        "                elif qmark_pos >= 0:\n",
        "                    # Move text before question mark to question\n",
        "                    current_qtext += \" \" + first_opt[:qmark_pos+1].strip()\n",
        "                    current_opts[0] = first_opt[qmark_pos+1:].strip()\n",
        "\n",
        "            if not (current_qtext.endswith(':') or current_qtext.endswith('?')):\n",
        "                warning = f\"Final question {current_qnum} has no proper ending\"\n",
        "                warnings.append(warning)\n",
        "                print(f\"WARNING: {warning}\")\n",
        "\n",
        "        # Now finalize the question with whatever options we found\n",
        "        questions.append(create_formatted_question(\n",
        "            exam_type,\n",
        "            year,\n",
        "            current_qnum,\n",
        "            current_qtext,\n",
        "            current_opts,\n",
        "            source_file,\n",
        "            i + 1\n",
        "        ))\n",
        "\n",
        "    # Final verification of sequential numbering\n",
        "    question_numbers = [q.get('_metadata', {}).get('original_number', 0) for q in questions if '_metadata' in q]\n",
        "    question_numbers.sort()\n",
        "\n",
        "    if question_numbers:\n",
        "        print(f\"Extracted question numbers: {min(question_numbers)} to {max(question_numbers)}\")\n",
        "\n",
        "        # Check for gaps\n",
        "        gaps = []\n",
        "        for j in range(len(question_numbers)-1):\n",
        "            if question_numbers[j+1] - question_numbers[j] > 1:\n",
        "                gap = (question_numbers[j], question_numbers[j+1])\n",
        "                missing = list(range(question_numbers[j]+1, question_numbers[j+1]))\n",
        "                gaps.append((gap, missing))\n",
        "\n",
        "        if gaps:\n",
        "            print(f\"WARNING: Found {len(gaps)} gaps in question numbering:\")\n",
        "            for (start, end), missing in gaps[:5]:  # Show first 5 gaps\n",
        "                warning = f\"Missing questions between {start} and {end}: {missing}\"\n",
        "                warnings.append(warning)\n",
        "                print(f\"  {warning}\")\n",
        "            if len(gaps) > 5:\n",
        "                print(f\"  ... and {len(gaps)-5} more gaps\")\n",
        "\n",
        "    # Final summary\n",
        "    if warnings:\n",
        "        print(f\"\\nExtraction completed with {len(warnings)} warnings\")\n",
        "        print(f\"Successfully extracted {len(questions)} questions\")\n",
        "    else:\n",
        "        print(f\"\\nExtraction completed successfully with no warnings\")\n",
        "        print(f\"Successfully extracted {len(questions)} questions\")\n",
        "\n",
        "    # Return both the questions and the warnings\n",
        "    return questions, warnings\n",
        "\n",
        "\n",
        "def clean_output_for_export(questions: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Prepare questions for export by removing metadata fields\n",
        "    \"\"\"\n",
        "    cleaned = []\n",
        "    for q in questions:\n",
        "        # Create a copy without the metadata\n",
        "        cleaned_q = {k: v for k, v in q.items() if not k.startswith('_')}\n",
        "        cleaned.append(cleaned_q)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def export_questions(questions: List[Dict], output_dir: str,\n",
        "                    exam_type: str = \"MIR\", year: str = \"2024\",\n",
        "                    version: str = \"v01\", question_type: str = \"t01\") -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Export questions to CSV and JSON files with standardized naming\n",
        "    \"\"\"\n",
        "    if not questions:\n",
        "        return None, None\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Format the filename according to requirements\n",
        "    filename_base = f\"{exam_type}-{year}-{version}-{question_type}\"\n",
        "\n",
        "    # Clean the questions for export (remove metadata)\n",
        "    export_questions = clean_output_for_export(questions)\n",
        "\n",
        "    # Export to JSON\n",
        "    json_path = os.path.join(output_dir, f\"{filename_base}.json\")\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_questions, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Export to CSV (flattening the options dictionary)\n",
        "    df = pd.DataFrame(questions)\n",
        "\n",
        "    # Extract options from the nested dictionary for CSV format\n",
        "    if not df.empty and 'options' in df.columns:\n",
        "        for key in ['A', 'B', 'C', 'D']:\n",
        "            df[f'option_{key}'] = df['options'].apply(lambda x: x.get(key, ''))\n",
        "        df = df.drop(columns=['options'])\n",
        "\n",
        "    # Remove metadata columns\n",
        "    if '_metadata' in df.columns:\n",
        "        metadata_df = pd.json_normalize(df['_metadata'])\n",
        "        df = pd.concat([df.drop(columns=['_metadata']), metadata_df], axis=1)\n",
        "\n",
        "    # Export to CSV\n",
        "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
        "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    return json_path, csv_path\n",
        "\n",
        "\n",
        "def process_directory(pdf_dir: str, output_dir: str, start_page: int = 2) -> None:\n",
        "    \"\"\"\n",
        "    Process all PDFs in a directory and export questions\n",
        "    Includes detailed warnings about extraction issues\n",
        "    \"\"\"\n",
        "    all_questions = []\n",
        "    all_warnings = []\n",
        "\n",
        "    # Process all PDFs\n",
        "    for filename in sorted(os.listdir(pdf_dir)):\n",
        "        if not filename.lower().endswith(\".pdf\"):\n",
        "            continue\n",
        "\n",
        "        pdf_path = os.path.join(pdf_dir, filename)\n",
        "        exam_type, year = get_exam_metadata(filename)\n",
        "\n",
        "        try:\n",
        "            questions, warnings = process_pdf(pdf_path, start_page=start_page)\n",
        "            all_questions.extend(questions)\n",
        "\n",
        "            # Record detailed warnings with file information\n",
        "            file_warnings = [{\"file\": filename, \"warning\": w} for w in warnings]\n",
        "            all_warnings.extend(file_warnings)\n",
        "\n",
        "            print(f\"Extracted {len(questions)} questions from {filename} ({exam_type} {year}) with {len(warnings)} warnings\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error processing {filename}: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            all_warnings.append({\"file\": filename, \"warning\": error_msg})\n",
        "\n",
        "    # Group questions by exam type and year\n",
        "    grouped_questions = {}\n",
        "    for q in all_questions:\n",
        "        # Extract exam type and year from question ID\n",
        "        id_parts = q['id'].split('-')\n",
        "        if len(id_parts) >= 2:\n",
        "            exam_type, year = id_parts[0], id_parts[1]\n",
        "            key = f\"{exam_type}-{year}\"\n",
        "\n",
        "            if key not in grouped_questions:\n",
        "                grouped_questions[key] = []\n",
        "\n",
        "            grouped_questions[key].append(q)\n",
        "\n",
        "    # Export each group separately\n",
        "    for key, questions in grouped_questions.items():\n",
        "        exam_type, year = key.split('-')\n",
        "\n",
        "        # Export with standard naming\n",
        "        json_path, csv_path = export_questions(\n",
        "            questions,\n",
        "            output_dir,\n",
        "            exam_type=exam_type,\n",
        "            year=year\n",
        "        )\n",
        "\n",
        "        if json_path:\n",
        "            print(f\"Exported {len(questions)} {exam_type} {year} questions to:\")\n",
        "            print(f\"  - JSON: {os.path.basename(json_path)}\")\n",
        "            print(f\"  - CSV: {os.path.basename(csv_path)}\")\n",
        "\n",
        "    # Export warnings to CSV\n",
        "    if all_warnings:\n",
        "        warnings_df = pd.DataFrame(all_warnings)\n",
        "        warnings_path = os.path.join(output_dir, \"extraction_warnings.csv\")\n",
        "        warnings_df.to_csv(warnings_path, index=False)\n",
        "        print(f\"\\nExported {len(all_warnings)} warnings to {warnings_path}\")"
      ],
      "metadata": {
        "id": "nqL0gp4SuK9c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option to upload PDFs directly to Colab (if not already in Drive)\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "def upload_pdfs_to_drive():\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            dest_path = os.path.join(PDF_DIR, filename)\n",
        "            with open(dest_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "            print(f\"Saved {filename} to {dest_path}\")\n",
        "\n",
        "# Uncomment the line below to upload PDF files\n",
        "# upload_pdfs_to_drive()"
      ],
      "metadata": {
        "id": "3NzTN-k-uUD5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List PDF files available for processing\n",
        "pdf_files = [f for f in os.listdir(PDF_DIR) if f.lower().endswith('.pdf')]\n",
        "print(f\"Found {len(pdf_files)} PDF files in {PDF_DIR}:\")\n",
        "for i, file in enumerate(pdf_files, 1):\n",
        "    print(f\"{i}. {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViGfv8IiucR9",
        "outputId": "df227755-b1fe-43f0-8636-2e07e8f9cbf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 PDF files in /content/MELIDA/data/raw/exams:\n",
            "1. Cuaderno_2024_MEDICINA_0_C.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process all PDFs in the directory\n",
        "process_directory(PDF_DIR, OUTPUT_DIR, start_page=2)"
      ],
      "metadata": {
        "id": "BZTBgVROugXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c827dc-af5e-4717-9f3c-e4cf04cb9355"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 217 questions from Cuaderno_2024_MEDICINA_0_C.pdf (MIR 2024)\n",
            "Exported 217 MIR 2024 questions to:\n",
            "  - JSON: MIR-2024-v01-t01.json\n",
            "  - CSV: MIR-2024-v01-t01.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERIFICATION CELL: Check for questions without proper endings before export\n",
        "def verify_questions_in_json_files(output_dir):\n",
        "    all_issues = []\n",
        "    total_questions = 0\n",
        "\n",
        "    # Process each JSON file in the output directory\n",
        "    for json_file in [f for f in os.listdir(output_dir) if f.lower().endswith('.json')]:\n",
        "        file_path = os.path.join(output_dir, json_file)\n",
        "        file_issues = []\n",
        "\n",
        "        try:\n",
        "            # Load the questions from the JSON file\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                questions = json.load(f)\n",
        "\n",
        "            total_questions += len(questions)\n",
        "\n",
        "            # Check each question\n",
        "            for i, q in enumerate(questions):\n",
        "                question_text = q.get('question_text', '').strip()\n",
        "\n",
        "                if not (question_text.endswith(':') or question_text.endswith('?')):\n",
        "                    file_issues.append({\n",
        "                        'index': i,\n",
        "                        'id': q.get('id', 'unknown'),\n",
        "                        'text': question_text,\n",
        "                        'file': json_file,\n",
        "                        'source_file': q.get('_metadata', {}).get('source_file', 'unknown') if '_metadata' in q else 'unknown',\n",
        "                        'page_number': q.get('_metadata', {}).get('page_number', 'unknown') if '_metadata' in q else 'unknown'\n",
        "                    })\n",
        "\n",
        "            all_issues.extend(file_issues)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {json_file}: {str(e)}\")\n",
        "\n",
        "    # Report results\n",
        "    print(f\"Total questions checked: {total_questions}\")\n",
        "\n",
        "    if all_issues:\n",
        "        print(f\"WARNING: Found {len(all_issues)} questions without proper endings (: or ?)\")\n",
        "        print(\"First 5 issues:\")\n",
        "        for i, issue in enumerate(all_issues[:5]):\n",
        "            print(f\"{i+1}. ID: {issue['id']}\")\n",
        "            print(f\"   Text: {issue['text']}\")\n",
        "            print(f\"   File: {issue['file']}\")\n",
        "            print(f\"   Source: {issue['source_file']}, Page: {issue['page_number']}\")\n",
        "\n",
        "        # Export issues to CSV\n",
        "        issues_df = pd.DataFrame(all_issues)\n",
        "        issues_csv = os.path.join(output_dir, \"question_ending_issues.csv\")\n",
        "        issues_df.to_csv(issues_csv, index=False)\n",
        "        print(f\"Exported all {len(all_issues)} issues to {issues_csv}\")\n",
        "    else:\n",
        "        print(\"VERIFICATION PASSED: All questions end with ':' or '?'\")\n",
        "\n",
        "    return all_issues\n",
        "\n",
        "# Verify questions after processing by reading the output JSON files\n",
        "print(\"\\nVerifying question formatting...\")\n",
        "question_issues = verify_questions_in_json_files(OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5vvPEEq5JIz",
        "outputId": "7d51beaa-e7bf-4936-9e1f-21edf1008553"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verifying question formatting...\n",
            "Total questions checked: 217\n",
            "WARNING: Found 8 questions without proper endings (: or ?)\n",
            "First 5 issues:\n",
            "1. ID: MIR-2024-v01-t01-Q045\n",
            "   Text: En un metaanálisis, el riesgo relativo estimado para la asociación causal entre el uso de mascarilla y la incidencia de SARS-CoV-2 fue de 0,\n",
            "   File: MIR-2024-v01-t01.json\n",
            "   Source: unknown, Page: unknown\n",
            "2. ID: MIR-2024-v01-t01-Q090\n",
            "   Text: Paciente de 75 años con estancia prolongada en UCI. En una exploración rutinaria se observa dificultad para la flexión dorsal del pie izquierdo con un tibial anterior a 1/5, una dificultad para la extensión de los dedos 1/5 y dificultad para la eversión con peroneos 3/\n",
            "   File: MIR-2024-v01-t01.json\n",
            "   Source: unknown, Page: unknown\n",
            "3. ID: MIR-2024-v01-t01-Q113\n",
            "   Text: Paciente con asma mal controlada a pesar de una combinación de glucocorticoides inhalados a dosis altas y un broncodilatador β-agonista de acción prolongada. Ha requerido ciclos de corticoides sistémicos sin una respuesta adecuada. Presenta rinosinusitis crónica con poliposis nasal y un recuento de eosinófilos de 400 células/μL en la analítica. Señale la respuesta correcta en cuanto al fenotipo asmático y la mejor opción de tratamiento. 1. Se trata de un asma eosinofílica (T2) y una buena opción de tratamiento sería añadir omalizumab. 2. Se trata de un asma eosinofílica (T2) y una buena opción de tratamiento sería añadir mepolizumab. 3. Se trata de un asma no T2 y la mejor opción de tratamiento sería un antileucotrieno. 4. Se trata de un asma no T2 y la mejor opción de tratamiento sería añadir benralizumab. 17 de 33\n",
            "   File: MIR-2024-v01-t01.json\n",
            "   Source: unknown, Page: unknown\n",
            "4. ID: MIR-2024-v01-t01-Q169\n",
            "   Text: Hombre de 53 años, sin antecedentes patológicos, acude al hospital por fiebre de 10 días de evolución, con intensa cefalea retroorbitaria y una importante sensación de fatiga. No refiere dolor musculoesquelético, lesiones cutáneas ni ningún otro síntoma acompañante. A lo largo de 15 días de ingreso se objetiva fiebre persistente y la aparición de discreta ictericia conjuntival. La exploración respiratoria, cardíaca, abdominal y neurológica es normal. La analítica muestra VSG 97 mm/h, PCR 24,5 mg/dL, GOT 156 U/L, GPT 148 U/L, FA 410 U/L, GGT 794 U/L, bilirrubina total 5,5 mg/dL a expensas de la bilirrubina directa, hemoglobina 11,5 g/dL, recuento leucocitario normal, plaquetas 648.000/mm3, función renal e ionograma normales, tiempo de protrombina normal pero TTPA ratio 1,\n",
            "   File: MIR-2024-v01-t01.json\n",
            "   Source: unknown, Page: unknown\n",
            "5. ID: MIR-2024-v01-t01-Q008\n",
            "   Text: Los anticuerpos antinucleares (ANA) son positivos a títulos 1/\n",
            "   File: MIR-2024-v01-t01.json\n",
            "   Source: unknown, Page: unknown\n",
            "Exported all 8 issues to /content/MELIDA/data/questions/question_ending_issues.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List processed output files\n",
        "json_files = [f for f in os.listdir(OUTPUT_DIR) if f.lower().endswith('.json')]\n",
        "print(f\"Found {len(json_files)} processed JSON files in {OUTPUT_DIR}:\")\n",
        "for i, file in enumerate(json_files, 1):\n",
        "    print(f\"{i}. {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeSNroYhuiTH",
        "outputId": "073abd0a-d425-4047-c10a-398106f38cab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 processed JSON files in /content/MELIDA/data/questions:\n",
            "1. MIR-2024-v01-t01.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview a sample from the first JSON file\n",
        "if json_files:\n",
        "    sample_file = os.path.join(OUTPUT_DIR, json_files[0])\n",
        "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Sample file: {json_files[0]}\")\n",
        "    print(f\"Total questions: {len(data)}\")\n",
        "    print(\"\\nSample questions (first 2):\")\n",
        "\n",
        "    for i, q in enumerate(data[:2], 1):\n",
        "        print(f\"\\nQuestion {i}:\")\n",
        "        print(f\"ID: {q['id']}\")\n",
        "        print(f\"Text: {q['question_text']}\")\n",
        "        print(\"Options:\")\n",
        "        for key, value in q['options'].items():\n",
        "            print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "id": "FjcOt3R7ukJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacf1a2e-f630-4004-c063-2fbdcf3ad5d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample file: MIR-2024-v01-t01.json\n",
            "Total questions: 217\n",
            "\n",
            "Sample questions (first 2):\n",
            "\n",
            "Question 1:\n",
            "ID: MIR-2024-v01-t01-Q001\n",
            "Text: Pregunta asociada a la imagen 1. Mujer de 42 años que acude a la consulta de genética por un diagnóstico reciente de cáncer de endometrio. En base a los antecedentes familiares que constan en la imagen, ¿cuál de los siguientes síndromes es más probable que presente?:\n",
            "Options:\n",
            "  A: Poliposis adenomatosa familiar.\n",
            "  B: Síndrome de Lynch.\n",
            "  C: Síndrome de cáncer de mama y ovario hereditario.\n",
            "  D: Síndrome de Cowden.\n",
            "\n",
            "Question 2:\n",
            "ID: MIR-2024-v01-t01-Q002\n",
            "Text: Pregunta asociada a la imagen 2. Paciente de 65 años que acude a urgencias por disminución brusca de agudeza visual en ojo derecho. La retinografía de dicho ojo se muestra en la imagen. Uno de los siguientes tratamientos está indicado para una enfermedad que es un factor de riesgo para esta situación. Indique cuál:\n",
            "Options:\n",
            "  A: Latanoprost y timolol.\n",
            "  B: Flecainida.\n",
            "  C: Hidroxicloroquina.\n",
            "  D: Complejos vitamínicos y antioxidantes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for questions that don't end with \":\" or \"?\"\n",
        "def check_question_endings(json_files_dir):\n",
        "    issues_found = []\n",
        "    total_questions = 0\n",
        "\n",
        "    # Process each JSON file\n",
        "    for json_file in [f for f in os.listdir(json_files_dir) if f.lower().endswith('.json')]:\n",
        "        file_path = os.path.join(json_files_dir, json_file)\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                questions = json.load(f)\n",
        "\n",
        "            # Check each question in the file\n",
        "            for q in questions:\n",
        "                total_questions += 1\n",
        "                question_text = q.get('question_text', '').strip()\n",
        "\n",
        "                if not (question_text.endswith(':') or question_text.endswith('?')):\n",
        "                    issues_found.append({\n",
        "                        'id': q.get('id', 'unknown'),\n",
        "                        'file': json_file,\n",
        "                        'text': question_text,\n",
        "                        'last_char': question_text[-1] if question_text else 'empty'\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {json_file}: {str(e)}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Total questions analyzed: {total_questions}\")\n",
        "\n",
        "    # Calculate percentage with proper error handling\n",
        "    percentage = (len(issues_found)/total_questions)*100 if total_questions > 0 else 0\n",
        "    print(f\"Questions without proper ending (: or ?): {len(issues_found)} ({percentage:.2f}%)\")\n",
        "\n",
        "    # Print details of problematic questions\n",
        "    if issues_found:\n",
        "        print(\"\\nQuestions with improper endings:\")\n",
        "        for i, issue in enumerate(issues_found[:10], 1):  # Show first 10 issues\n",
        "            print(f\"{i}. ID: {issue['id']} (from {issue['file']})\")\n",
        "            print(f\"   Text: {issue['text'][:100]}...\")\n",
        "            print(f\"   Last character: '{issue['last_char']}'\")\n",
        "\n",
        "        if len(issues_found) > 10:\n",
        "            print(f\"\\n... and {len(issues_found) - 10} more issues.\")\n",
        "\n",
        "    return issues_found\n",
        "\n",
        "# Run the check on the output directory\n",
        "print(\"Checking question formatting...\")\n",
        "issues = check_question_endings(OUTPUT_DIR)\n",
        "\n",
        "# Optional: Export issues to CSV for further analysis\n",
        "if issues and len(issues) > 0:\n",
        "    issues_df = pd.DataFrame(issues)\n",
        "    issues_csv = os.path.join(OUTPUT_DIR, \"question_format_issues.csv\")\n",
        "    issues_df.to_csv(issues_csv, index=False)\n",
        "    print(f\"\\nExported {len(issues)} issues to {issues_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EumK2Zb30u0x",
        "outputId": "18253b7f-da94-44aa-e2f8-8d63ac6ad16b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking question formatting...\n",
            "Total questions analyzed: 217\n",
            "Questions without proper ending (: or ?): 8 (3.69%)\n",
            "\n",
            "Questions with improper endings:\n",
            "1. ID: MIR-2024-v01-t01-Q045 (from MIR-2024-v01-t01.json)\n",
            "   Text: En un metaanálisis, el riesgo relativo estimado para la asociación causal entre el uso de mascarilla...\n",
            "   Last character: ','\n",
            "2. ID: MIR-2024-v01-t01-Q090 (from MIR-2024-v01-t01.json)\n",
            "   Text: Paciente de 75 años con estancia prolongada en UCI. En una exploración rutinaria se observa dificult...\n",
            "   Last character: '/'\n",
            "3. ID: MIR-2024-v01-t01-Q113 (from MIR-2024-v01-t01.json)\n",
            "   Text: Paciente con asma mal controlada a pesar de una combinación de glucocorticoides inhalados a dosis al...\n",
            "   Last character: '3'\n",
            "4. ID: MIR-2024-v01-t01-Q169 (from MIR-2024-v01-t01.json)\n",
            "   Text: Hombre de 53 años, sin antecedentes patológicos, acude al hospital por fiebre de 10 días de evolució...\n",
            "   Last character: ','\n",
            "5. ID: MIR-2024-v01-t01-Q008 (from MIR-2024-v01-t01.json)\n",
            "   Text: Los anticuerpos antinucleares (ANA) son positivos a títulos 1/...\n",
            "   Last character: '/'\n",
            "6. ID: MIR-2024-v01-t01-Q170 (from MIR-2024-v01-t01.json)\n",
            "   Text: Hombre de 38 años con dependencia alcohólica grave. Ha tenido varios ingresos por pancreatitis aguda...\n",
            "   Last character: '2'\n",
            "7. ID: MIR-2024-v01-t01-Q173 (from MIR-2024-v01-t01.json)\n",
            "   Text: Hombre de 55 años con antecedentes de cáncer de pulmón (estadio IV). Su madre murió a los 65 años po...\n",
            "   Last character: '/'\n",
            "8. ID: MIR-2024-v01-t01-Q199 (from MIR-2024-v01-t01.json)\n",
            "   Text: Hombre de 45 años con antecedentes personales de hipertensión arterial, dislipemia, hígado graso y e...\n",
            "   Last character: 'e'\n",
            "\n",
            "Exported 8 issues to /content/MELIDA/data/questions/question_format_issues.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a specific file\n",
        "def download_file(file_path):\n",
        "    try:\n",
        "        files.download(file_path)\n",
        "        print(f\"Started download of {os.path.basename(file_path)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading file: {str(e)}\")\n",
        "\n",
        "# Example usage - uncomment to download a specific file\n",
        "# if json_files:\n",
        "#     download_file(os.path.join(OUTPUT_DIR, json_files[0]))\n",
        "\n",
        "# Create a zip file with all processed files for easier download\n",
        "import zipfile\n",
        "\n",
        "def create_and_download_zip():\n",
        "    zip_path = os.path.join(BASE_PATH, \"processed_questions.zip\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for file in os.listdir(OUTPUT_DIR):\n",
        "            file_path = os.path.join(OUTPUT_DIR, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                zipf.write(file_path, arcname=file)\n",
        "\n",
        "    download_file(zip_path)\n",
        "    print(f\"All processed files zipped to {zip_path}\")\n",
        "\n",
        "# Uncomment to create and download a zip of all processed files\n",
        "# create_and_download_zip()"
      ],
      "metadata": {
        "id": "dGOTlaDfu7nT"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}