{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2UYviwaKZP92oDJGZ+ZwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armelida/MELIDA/blob/main/src/questions-scraper/MELIDA_PDF_Scraper_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2YwGaUcetnwH"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install pdfplumber pandas --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pdfplumber pandas --quiet"
      ],
      "metadata": {
        "id": "o6bR_lp8t-_j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure paths\n",
        "import os\n",
        "\n",
        "# Update this path based on your Drive structure\n",
        "BASE_PATH = \"/content/drive/MyDrive/MELIDA\"  # Adjust this path as needed\n",
        "\n",
        "# Define specific paths\n",
        "PDF_DIR = os.path.join(BASE_PATH, \"data/raw/exams\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"data/questions\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"PDF Directory: {PDF_DIR}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ps_aBquEIu",
        "outputId": "0508ced1-edae-499b-81a6-5efd88b012f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Directory: /content/drive/MyDrive/MELIDA/data/raw/exams\n",
            "Output Directory: /content/drive/MyDrive/MELIDA/data/questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "\n",
        "def get_exam_metadata(filename: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extracts exam type and year from filename\n",
        "    Example: 'Cuaderno_2024_MEDICINA_0_C.pdf' -> ('MIR', '2024')\n",
        "    Adjust patterns as needed for different exam types\n",
        "    \"\"\"\n",
        "    # Default values\n",
        "    exam_type = \"MIR\"\n",
        "    year = \"UNKNOWN\"\n",
        "\n",
        "    # Extract year\n",
        "    year_match = re.search(r'(\\d{4})', filename)\n",
        "    if year_match:\n",
        "        year = year_match.group(1)\n",
        "\n",
        "    # Extract exam type if present (customize based on your naming conventions)\n",
        "    if \"MEDICINA\" in filename.upper():\n",
        "        exam_type = \"MIR\"\n",
        "    elif \"ENFERMERIA\" in filename.upper():\n",
        "        exam_type = \"EIR\"\n",
        "    # Add more exam types as needed\n",
        "\n",
        "    return exam_type, year\n",
        "\n",
        "\n",
        "def format_question_id(exam_type: str, year: str, version: str = \"v01\",\n",
        "                       question_type: str = \"t01\", question_num: int = 0) -> str:\n",
        "    \"\"\"\n",
        "    Creates standardized question ID\n",
        "    Format: {exam_type}-{year}-{version}-{question_type}-Q{question_num:03d}\n",
        "    Example: MIR-2024-v01-t01-Q026\n",
        "    \"\"\"\n",
        "    return f\"{exam_type}-{year}-{version}-{question_type}-Q{question_num:03d}\"\n",
        "\n",
        "\n",
        "def create_formatted_question(exam_type: str, year: str, qnum: int,\n",
        "                             qtext: str, options: List[str],\n",
        "                             source_file: str, page_num: int) -> Dict:\n",
        "    \"\"\"\n",
        "    Creates a question dict with the required format\n",
        "    \"\"\"\n",
        "    # Clean the question text\n",
        "    text = re.sub(r'\\s+', ' ', qtext).strip()\n",
        "    text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)  # Merge hyphen-split\n",
        "    text = re.sub(r'\\[(.*?)\\]', r'\\1', text)       # Remove bracket formatting\n",
        "\n",
        "    # Format options as required dictionary with A, B, C, D keys\n",
        "    option_dict = {}\n",
        "    option_keys = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "    for i, opt in enumerate(options):\n",
        "        if i < len(option_keys):\n",
        "            opt = re.sub(r'\\s+', ' ', opt).strip()\n",
        "            option_dict[option_keys[i]] = opt\n",
        "\n",
        "    # Ensure all options exist even if empty\n",
        "    for key in option_keys:\n",
        "        if key not in option_dict:\n",
        "            option_dict[key] = \"\"\n",
        "\n",
        "    # Create the question object in the required format\n",
        "    return {\n",
        "        \"id\": format_question_id(exam_type, year, question_num=qnum),\n",
        "        \"question_text\": text,\n",
        "        \"options\": option_dict,\n",
        "        # Metadata fields (not in final output but useful for debugging)\n",
        "        \"_metadata\": {\n",
        "            \"source_file\": source_file,\n",
        "            \"page_number\": page_num,\n",
        "            \"original_number\": qnum\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_lines_with_x0(page, bbox):\n",
        "    \"\"\"\n",
        "    Crops to bbox, extracts text lines as (text, x0).\n",
        "    Merges lines ending in '-'.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    hyphen_buffer = \"\"\n",
        "\n",
        "    cropped = page.crop(bbox)\n",
        "    raw_lines = cropped.extract_text_lines()\n",
        "\n",
        "    for ln in raw_lines:\n",
        "        text = ln[\"text\"].strip()\n",
        "        x0_val = ln[\"x0\"]\n",
        "\n",
        "        if hyphen_buffer:\n",
        "            text = hyphen_buffer + text\n",
        "            hyphen_buffer = \"\"\n",
        "\n",
        "        if re.search(r'-\\s*$', text):\n",
        "            hyphen_buffer = re.sub(r'-\\s*$', '', text)\n",
        "            continue\n",
        "\n",
        "        lines.append((text, x0_val))\n",
        "    return lines\n",
        "\n",
        "\n",
        "def split_markers(line_text):\n",
        "    \"\"\"\n",
        "    Splits on every '(\\\\d+)\\\\. ' pattern.\n",
        "    Returns [(num_str_or_None, snippet)].\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'(\\d+)\\.\\s')\n",
        "    tokens = pattern.split(line_text)\n",
        "\n",
        "    results = []\n",
        "    leftover = tokens[0].strip()\n",
        "    if leftover:\n",
        "        results.append((None, leftover))\n",
        "\n",
        "    i = 1\n",
        "    while i < len(tokens):\n",
        "        num_str = tokens[i]\n",
        "        i += 1\n",
        "        snippet = tokens[i].strip() if i < len(tokens) else \"\"\n",
        "        i += 1\n",
        "        results.append((num_str, snippet))\n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_lines(\n",
        "    lines, page_idx, exam_type, year, source_file,\n",
        "    questions,\n",
        "    current_qnum, current_qtext, current_opts\n",
        "):\n",
        "    \"\"\"\n",
        "    State machine logic to extract questions and options\n",
        "    \"\"\"\n",
        "    MAX_QNUM = 210\n",
        "\n",
        "    for (full_line, _x0) in lines:\n",
        "        if not full_line.strip():\n",
        "            continue\n",
        "\n",
        "        segments = split_markers(full_line)\n",
        "\n",
        "        for (num_str, snippet) in segments:\n",
        "            snippet = snippet.strip()\n",
        "\n",
        "            if num_str is not None:\n",
        "                val = int(num_str)\n",
        "\n",
        "                # CASE A: Potential option if 1..4\n",
        "                if 1 <= val <= 4:\n",
        "                    # If we have a current question and fewer than 4 options, treat as new option\n",
        "                    if current_qnum is not None and len(current_opts) < 4:\n",
        "                        current_opts.append(snippet)\n",
        "                    else:\n",
        "                        # Otherwise, this is a new question\n",
        "                        # finalize old question if any\n",
        "                        if current_qnum is not None:\n",
        "                            questions.append(create_formatted_question(\n",
        "                                exam_type,\n",
        "                                year,\n",
        "                                current_qnum,\n",
        "                                current_qtext,\n",
        "                                current_opts,\n",
        "                                source_file,\n",
        "                                page_idx + 1\n",
        "                            ))\n",
        "                        current_qnum = val\n",
        "                        current_qtext = snippet\n",
        "                        current_opts = []\n",
        "\n",
        "                # CASE B: question # in [5..210] or we have 4 options already\n",
        "                else:\n",
        "                    if val <= MAX_QNUM:\n",
        "                        # finalize old question if any\n",
        "                        if current_qnum is not None:\n",
        "                            questions.append(create_formatted_question(\n",
        "                                exam_type,\n",
        "                                year,\n",
        "                                current_qnum,\n",
        "                                current_qtext,\n",
        "                                current_opts,\n",
        "                                source_file,\n",
        "                                page_idx + 1\n",
        "                            ))\n",
        "                        # Start new question\n",
        "                        current_qnum = val\n",
        "                        current_qtext = snippet\n",
        "                        current_opts = []\n",
        "                    else:\n",
        "                        # out of range => just leftover text\n",
        "                        if current_opts:\n",
        "                            current_opts[-1] += f\" {val}. {snippet}\"\n",
        "                        elif current_qnum is not None:\n",
        "                            current_qtext += f\" {val}. {snippet}\"\n",
        "\n",
        "            else:\n",
        "                # leftover text\n",
        "                if current_qnum is not None and current_opts:\n",
        "                    # append to last option\n",
        "                    current_opts[-1] += \" \" + snippet\n",
        "                elif current_qnum is not None:\n",
        "                    # append to question text\n",
        "                    current_qtext += \" \" + snippet\n",
        "                # else we have no active question => ignore\n",
        "\n",
        "    return current_qnum, current_qtext, current_opts\n",
        "\n",
        "\n",
        "def process_pdf(pdf_path: str, start_page: int = 2) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Process PDF and extract questions with options\n",
        "    \"\"\"\n",
        "    questions = []\n",
        "    current_qnum = None\n",
        "    current_qtext = \"\"\n",
        "    current_opts = []\n",
        "\n",
        "    # Extract metadata from filename\n",
        "    filename = os.path.basename(pdf_path)\n",
        "    exam_type, year = get_exam_metadata(filename)\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        source_file = os.path.basename(pdf_path)\n",
        "        num_pages = len(pdf.pages)\n",
        "\n",
        "        for i in range(start_page, num_pages):\n",
        "            page = pdf.pages[i]\n",
        "            w, h = page.width, page.height\n",
        "            mid_x = w / 2.0\n",
        "\n",
        "            # Split page into left and right columns\n",
        "            left_bbox = (0, 0, mid_x, h)\n",
        "            right_bbox = (mid_x, 0, w, h)\n",
        "\n",
        "            left_lines = extract_lines_with_x0(page, left_bbox)\n",
        "            right_lines = extract_lines_with_x0(page, right_bbox)\n",
        "\n",
        "            # Parse left column\n",
        "            current_qnum, current_qtext, current_opts = parse_lines(\n",
        "                left_lines, i, exam_type, year, source_file,\n",
        "                questions,\n",
        "                current_qnum, current_qtext, current_opts\n",
        "            )\n",
        "\n",
        "            # Parse right column\n",
        "            current_qnum, current_qtext, current_opts = parse_lines(\n",
        "                right_lines, i, exam_type, year, source_file,\n",
        "                questions,\n",
        "                current_qnum, current_qtext, current_opts\n",
        "            )\n",
        "\n",
        "    # Add the last question if not already added\n",
        "    if current_qnum is not None:\n",
        "        questions.append(create_formatted_question(\n",
        "            exam_type,\n",
        "            year,\n",
        "            current_qnum,\n",
        "            current_qtext,\n",
        "            current_opts,\n",
        "            source_file,\n",
        "            i + 1\n",
        "        ))\n",
        "\n",
        "    return questions\n",
        "\n",
        "\n",
        "def clean_output_for_export(questions: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Prepare questions for export by removing metadata fields\n",
        "    \"\"\"\n",
        "    cleaned = []\n",
        "    for q in questions:\n",
        "        # Create a copy without the metadata\n",
        "        cleaned_q = {k: v for k, v in q.items() if not k.startswith('_')}\n",
        "        cleaned.append(cleaned_q)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def export_questions(questions: List[Dict], output_dir: str,\n",
        "                    exam_type: str = \"MIR\", year: str = \"2024\",\n",
        "                    version: str = \"v01\", question_type: str = \"t01\") -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Export questions to CSV and JSON files with standardized naming\n",
        "    \"\"\"\n",
        "    if not questions:\n",
        "        return None, None\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Format the filename according to requirements\n",
        "    filename_base = f\"{exam_type}-{year}-{version}-{question_type}\"\n",
        "\n",
        "    # Clean the questions for export (remove metadata)\n",
        "    export_questions = clean_output_for_export(questions)\n",
        "\n",
        "    # Export to JSON\n",
        "    json_path = os.path.join(output_dir, f\"{filename_base}.json\")\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_questions, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Export to CSV (flattening the options dictionary)\n",
        "    df = pd.DataFrame(questions)\n",
        "\n",
        "    # Extract options from the nested dictionary for CSV format\n",
        "    if not df.empty and 'options' in df.columns:\n",
        "        for key in ['A', 'B', 'C', 'D']:\n",
        "            df[f'option_{key}'] = df['options'].apply(lambda x: x.get(key, ''))\n",
        "        df = df.drop(columns=['options'])\n",
        "\n",
        "    # Remove metadata columns\n",
        "    if '_metadata' in df.columns:\n",
        "        metadata_df = pd.json_normalize(df['_metadata'])\n",
        "        df = pd.concat([df.drop(columns=['_metadata']), metadata_df], axis=1)\n",
        "\n",
        "    # Export to CSV\n",
        "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
        "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    return json_path, csv_path\n",
        "\n",
        "\n",
        "def process_directory(pdf_dir: str, output_dir: str, start_page: int = 2) -> None:\n",
        "    \"\"\"\n",
        "    Process all PDFs in a directory and export questions\n",
        "    \"\"\"\n",
        "    all_questions = []\n",
        "    exam_types = set()\n",
        "    years = set()\n",
        "\n",
        "    # Process all PDFs\n",
        "    for filename in sorted(os.listdir(pdf_dir)):\n",
        "        if not filename.lower().endswith(\".pdf\"):\n",
        "            continue\n",
        "\n",
        "        pdf_path = os.path.join(pdf_dir, filename)\n",
        "        exam_type, year = get_exam_metadata(filename)\n",
        "        exam_types.add(exam_type)\n",
        "        years.add(year)\n",
        "\n",
        "        try:\n",
        "            questions = process_pdf(pdf_path, start_page=start_page)\n",
        "            all_questions.extend(questions)\n",
        "            print(f\"Extracted {len(questions)} questions from {filename} ({exam_type} {year})\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    # Group questions by exam type and year\n",
        "    grouped_questions = {}\n",
        "    for q in all_questions:\n",
        "        # Extract exam type and year from question ID\n",
        "        id_parts = q['id'].split('-')\n",
        "        if len(id_parts) >= 2:\n",
        "            exam_type, year = id_parts[0], id_parts[1]\n",
        "            key = f\"{exam_type}-{year}\"\n",
        "\n",
        "            if key not in grouped_questions:\n",
        "                grouped_questions[key] = []\n",
        "\n",
        "            grouped_questions[key].append(q)\n",
        "\n",
        "    # Export each group separately\n",
        "    for key, questions in grouped_questions.items():\n",
        "        exam_type, year = key.split('-')\n",
        "\n",
        "        # Export with standard naming\n",
        "        json_path, csv_path = export_questions(\n",
        "            questions,\n",
        "            output_dir,\n",
        "            exam_type=exam_type,\n",
        "            year=year\n",
        "        )\n",
        "\n",
        "        if json_path:\n",
        "            print(f\"Exported {len(questions)} {exam_type} {year} questions to:\")\n",
        "            print(f\"  - JSON: {os.path.basename(json_path)}\")\n",
        "            print(f\"  - CSV: {os.path.basename(csv_path)}\")"
      ],
      "metadata": {
        "id": "nqL0gp4SuK9c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option to upload PDFs directly to Colab (if not already in Drive)\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "def upload_pdfs_to_drive():\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            dest_path = os.path.join(PDF_DIR, filename)\n",
        "            with open(dest_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "            print(f\"Saved {filename} to {dest_path}\")\n",
        "\n",
        "# Uncomment the line below to upload PDF files\n",
        "# upload_pdfs_to_drive()"
      ],
      "metadata": {
        "id": "3NzTN-k-uUD5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List PDF files available for processing\n",
        "pdf_files = [f for f in os.listdir(PDF_DIR) if f.lower().endswith('.pdf')]\n",
        "print(f\"Found {len(pdf_files)} PDF files in {PDF_DIR}:\")\n",
        "for i, file in enumerate(pdf_files, 1):\n",
        "    print(f\"{i}. {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViGfv8IiucR9",
        "outputId": "efc8ab95-de58-4205-8a34-a0904da68645"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 PDF files in /content/drive/MyDrive/MELIDA/data/raw/exams:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process all PDFs in the directory\n",
        "process_directory(PDF_DIR, OUTPUT_DIR, start_page=2)"
      ],
      "metadata": {
        "id": "BZTBgVROugXK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List processed output files\n",
        "json_files = [f for f in os.listdir(OUTPUT_DIR) if f.lower().endswith('.json')]\n",
        "print(f\"Found {len(json_files)} processed JSON files in {OUTPUT_DIR}:\")\n",
        "for i, file in enumerate(json_files, 1):\n",
        "    print(f\"{i}. {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeSNroYhuiTH",
        "outputId": "a8bcef26-0d5d-4f57-f3d3-b746052860d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 processed JSON files in /content/drive/MyDrive/MELIDA/data/questions:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview a sample from the first JSON file\n",
        "if json_files:\n",
        "    sample_file = os.path.join(OUTPUT_DIR, json_files[0])\n",
        "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Sample file: {json_files[0]}\")\n",
        "    print(f\"Total questions: {len(data)}\")\n",
        "    print(\"\\nSample questions (first 2):\")\n",
        "\n",
        "    for i, q in enumerate(data[:2], 1):\n",
        "        print(f\"\\nQuestion {i}:\")\n",
        "        print(f\"ID: {q['id']}\")\n",
        "        print(f\"Text: {q['question_text']}\")\n",
        "        print(\"Options:\")\n",
        "        for key, value in q['options'].items():\n",
        "            print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "id": "FjcOt3R7ukJ0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a specific file\n",
        "def download_file(file_path):\n",
        "    try:\n",
        "        files.download(file_path)\n",
        "        print(f\"Started download of {os.path.basename(file_path)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading file: {str(e)}\")\n",
        "\n",
        "# Example usage - uncomment to download a specific file\n",
        "# if json_files:\n",
        "#     download_file(os.path.join(OUTPUT_DIR, json_files[0]))\n",
        "\n",
        "# Create a zip file with all processed files for easier download\n",
        "import zipfile\n",
        "\n",
        "def create_and_download_zip():\n",
        "    zip_path = os.path.join(BASE_PATH, \"processed_questions.zip\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for file in os.listdir(OUTPUT_DIR):\n",
        "            file_path = os.path.join(OUTPUT_DIR, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                zipf.write(file_path, arcname=file)\n",
        "\n",
        "    download_file(zip_path)\n",
        "    print(f\"All processed files zipped to {zip_path}\")\n",
        "\n",
        "# Uncomment to create and download a zip of all processed files\n",
        "# create_and_download_zip()"
      ],
      "metadata": {
        "id": "dGOTlaDfu7nT"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}