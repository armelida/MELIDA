{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8i3IC1lzcAjvP5oplriKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armelida/MELIDA/blob/main/src/questions-scraper/MELIDA_PDF_Scraper_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2YwGaUcetnwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c74c526-3c02-4447-b621-44e35fe2170a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Directory: /content/MELIDA/data/raw/exams\n",
            "Output Directory: /content/MELIDA/data/questions\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Environment setup, imports, and helper functions\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Configure paths (run this cell first)\n",
        "BASE_PATH = \"/content/MELIDA\"\n",
        "PDF_DIR = os.path.join(BASE_PATH, \"data/raw/exams\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"data/questions\")\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"PDF Directory: {PDF_DIR}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
        "\n",
        "def normalize_spaces(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    normalized = re.sub(r'\\s+', ' ', text)\n",
        "    return normalized.strip()\n",
        "\n",
        "def get_exam_metadata(filename: str) -> Tuple[str, str]:\n",
        "    exam_type = \"MIR\"\n",
        "    year = \"UNKNOWN\"\n",
        "    year_match = re.search(r'(\\d{4})', filename)\n",
        "    if year_match:\n",
        "        year = year_match.group(1)\n",
        "    if \"MEDICINA\" in filename.upper():\n",
        "        exam_type = \"MIR\"\n",
        "    elif \"ENFERMERIA\" in filename.upper():\n",
        "        exam_type = \"EIR\"\n",
        "    return exam_type, year\n",
        "\n",
        "def format_question_id(exam_type: str, year: str, version: str = \"v01\",\n",
        "                       question_type: str = \"t01\", question_num: int = 0) -> str:\n",
        "    return f\"{exam_type}-{year}-{version}-{question_type}-Q{question_num:03d}\"\n",
        "\n",
        "def create_formatted_question(exam_type: str, year: str, qnum: int,\n",
        "                              qtext: str, options: List[str],\n",
        "                              source_file: str, page_num: int) -> Dict:\n",
        "    text = normalize_spaces(qtext)\n",
        "    text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)\n",
        "    text = re.sub(r'\\[(.*?)\\]', r'\\1', text)\n",
        "    option_dict = {}\n",
        "    option_keys = [\"A\", \"B\", \"C\", \"D\"]\n",
        "    for i, opt in enumerate(options):\n",
        "        if i < len(option_keys):\n",
        "            opt = normalize_spaces(opt)\n",
        "            opt = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', opt)\n",
        "            option_dict[option_keys[i]] = opt\n",
        "    for key in option_keys:\n",
        "        if key not in option_dict:\n",
        "            option_dict[key] = \"\"\n",
        "    return {\n",
        "        \"id\": format_question_id(exam_type, year, question_num=qnum),\n",
        "        \"question_text\": text,\n",
        "        \"options\": option_dict,\n",
        "        \"_metadata\": {\n",
        "            \"source_file\": source_file,\n",
        "            \"page_number\": page_num,\n",
        "            \"original_number\": qnum\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1A: Export functions\n",
        "\n",
        "def clean_output_for_export(questions: List[Dict]) -> List[Dict]:\n",
        "    cleaned = []\n",
        "    for q in questions:\n",
        "        cleaned_q = {k: v for k, v in q.items() if not k.startswith('_')}\n",
        "        cleaned.append(cleaned_q)\n",
        "    return cleaned\n",
        "\n",
        "def export_questions(questions: List[Dict], output_dir: str,\n",
        "                     exam_type: str = \"MIR\", year: str = \"2024\",\n",
        "                     version: str = \"v01\", question_type: str = \"t01\") -> Tuple[str, str]:\n",
        "    if not questions:\n",
        "        return None, None\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    filename_base = f\"{exam_type}-{year}-{version}-{question_type}\"\n",
        "    export_qs = clean_output_for_export(questions)\n",
        "    for q in export_qs:\n",
        "        q['question_text'] = normalize_spaces(q['question_text'])\n",
        "        for key, value in q['options'].items():\n",
        "            q['options'][key] = normalize_spaces(value)\n",
        "    json_path = os.path.join(output_dir, f\"{filename_base}.json\")\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_qs, f, ensure_ascii=False, indent=2)\n",
        "    df = pd.DataFrame(questions)\n",
        "    if not df.empty and 'options' in df.columns:\n",
        "        for key in ['A', 'B', 'C', 'D']:\n",
        "            df[f'option_{key}'] = df['options'].apply(lambda x: x.get(key, ''))\n",
        "        df = df.drop(columns=['options'])\n",
        "    if '_metadata' in df.columns:\n",
        "        metadata_df = pd.json_normalize(df['_metadata'])\n",
        "        df = pd.concat([df.drop(columns=['_metadata']), metadata_df], axis=1)\n",
        "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
        "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "    return json_path, csv_path\n"
      ],
      "metadata": {
        "id": "zzLLg3RoUcEA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Extraction helper\n",
        "def extract_lines_with_x0(page, bbox):\n",
        "    lines = []\n",
        "    hyphen_buffer = \"\"\n",
        "    cropped = page.crop(bbox)\n",
        "    raw_lines = cropped.extract_text_lines()\n",
        "    for ln in raw_lines:\n",
        "        text = ln[\"text\"].strip()\n",
        "        # Skip page numbering lines (e.g., \"Página: 1 de 33\")\n",
        "        if re.match(r\"^Página:\\s*\\d+\\s*de\\s*\\d+$\", text):\n",
        "            continue\n",
        "        if hyphen_buffer:\n",
        "            text = hyphen_buffer + text\n",
        "            hyphen_buffer = \"\"\n",
        "        if re.search(r'-\\s*$', text):\n",
        "            hyphen_buffer = re.sub(r'-\\s*$', '', text)\n",
        "            continue\n",
        "        lines.append(text)\n",
        "    return lines\n"
      ],
      "metadata": {
        "id": "95R5kiXIScdR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Extraction using regex with warnings for jumps and option count\n",
        "\n",
        "def extract_questions_from_text(text: str, exam_type: str, year: str,\n",
        "                                source_file: str, page_num: int, min_valid: int = 26) -> Tuple[List[Dict], int]:\n",
        "    questions = []\n",
        "    expected_qnum = min_valid  # The sequential expected question number\n",
        "    # Regex pattern:\n",
        "    #  - (?P<orig_qnum>\\d+)\\.\\s+  captures the original question number from the text.\n",
        "    #  - (?!Pregunta asociada a la imagen) ensures we skip unwanted blocks.\n",
        "    #  - (?P<qtext>.*?(?:\\?|:)) captures the header (question text) ending with '?' or ':'.\n",
        "    #  - Then, we capture four options (each starting with a number and a dot).\n",
        "    #  - (?=\\d+\\.|$) stops when a new question marker starts or at the end of text.\n",
        "    pattern = (\n",
        "        r\"(?P<orig_qnum>\\d+)\\.\\s+\"\n",
        "        r\"(?!Pregunta asociada a la imagen)\"\n",
        "        r\"(?P<qtext>.*?(?:\\?|:))\\s+\"\n",
        "        r\"(?P<opt1>\\d+\\.\\s+.*?)(?P<opt2>\\d+\\.\\s+.*?)(?P<opt3>\\d+\\.\\s+.*?)(?P<opt4>\\d+\\.\\s+.*?)(?=\\d+\\.|$)\"\n",
        "    )\n",
        "    matches = list(re.finditer(pattern, text, re.DOTALL))\n",
        "    for m in matches:\n",
        "        orig_qnum_str = m.group(\"orig_qnum\")\n",
        "        try:\n",
        "            orig_qnum = int(orig_qnum_str)\n",
        "        except ValueError:\n",
        "            print(f\"WARNING: Could not convert original question number '{orig_qnum_str}' to int on page {page_num}.\")\n",
        "            continue\n",
        "\n",
        "        # Skip questions with a number below the valid minimum.\n",
        "        if orig_qnum < min_valid:\n",
        "            print(f\"Skipping question with number {orig_qnum} (min valid is {min_valid}) on page {page_num}.\")\n",
        "            continue\n",
        "\n",
        "        # Warn if the extracted question number does not match the expected sequential number.\n",
        "        if orig_qnum != expected_qnum:\n",
        "            print(f\"WARNING: Expected question number {expected_qnum} but found {orig_qnum} on page {page_num}.\")\n",
        "            # Reset expected_qnum to current extracted number for subsequent checks.\n",
        "            expected_qnum = orig_qnum\n",
        "\n",
        "        # Extract question text (header) and normalize spaces.\n",
        "        qtext = normalize_spaces(m.group(\"qtext\"))\n",
        "        # Reconstruct the full header (which should begin with the original number)\n",
        "        header = f\"{orig_qnum}. {qtext}\"\n",
        "        if not header.lstrip().startswith(f\"{orig_qnum}.\"):\n",
        "            print(f\"WARNING: Header for question {orig_qnum} on page {page_num} does not start as expected.\")\n",
        "\n",
        "        # Extract the four options.\n",
        "        opts = []\n",
        "        for opt_tag in [\"opt1\", \"opt2\", \"opt3\", \"opt4\"]:\n",
        "            opt_text = m.group(opt_tag)\n",
        "            # Remove the leading number and dot from each option.\n",
        "            opt_clean = re.sub(r\"^\\d+\\.\\s+\", \"\", opt_text)\n",
        "            opts.append(normalize_spaces(opt_clean))\n",
        "\n",
        "        if len(opts) != 4:\n",
        "            print(f\"WARNING: Question {orig_qnum} on page {page_num} has {len(opts)} options (expected 4).\")\n",
        "            continue\n",
        "\n",
        "        # Create the question using the original question number.\n",
        "        q = create_formatted_question(exam_type, year, orig_qnum, header, opts, source_file, page_num)\n",
        "        questions.append(q)\n",
        "        expected_qnum = orig_qnum + 1  # Expect the next question to have the next number.\n",
        "\n",
        "    return questions, expected_qnum\n"
      ],
      "metadata": {
        "id": "hyeNPGDISdl5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Updated process_pdf using the new extraction function\n",
        "def process_pdf(pdf_path: str, start_page: int = 2) -> Tuple[List[Dict], List[str]]:\n",
        "    questions = []\n",
        "    warnings = []\n",
        "    filename = os.path.basename(pdf_path)\n",
        "    exam_type, year = get_exam_metadata(filename)\n",
        "\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            source_file = os.path.basename(pdf_path)\n",
        "            num_pages = len(pdf.pages)\n",
        "            for i in range(start_page, num_pages):\n",
        "                page = pdf.pages[i]\n",
        "                w, h = page.width, page.height\n",
        "                mid_x = w / 2.0\n",
        "                left_bbox = (0, 0, mid_x, h)\n",
        "                right_bbox = (mid_x, 0, w, h)\n",
        "                left_lines = extract_lines_with_x0(page, left_bbox)\n",
        "                right_lines = extract_lines_with_x0(page, right_bbox)\n",
        "                all_lines = left_lines + right_lines\n",
        "                page_text = normalize_spaces(\" \".join(all_lines))\n",
        "                qs, _ = extract_questions_from_text(page_text, exam_type, year, source_file, i + 1, min_valid=26)\n",
        "                questions.extend(qs)\n",
        "        print(f\"Extraction completed successfully: {len(questions)} questions extracted.\")\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing {os.path.basename(pdf_path)}: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        warnings.append(error_msg)\n",
        "        questions = []\n",
        "    return questions, warnings\n"
      ],
      "metadata": {
        "id": "weyn5hyVShuY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Process directory using updated parsing and export results\n",
        "def process_directory(pdf_dir: str, output_dir: str, start_page: int = 2) -> None:\n",
        "    all_questions = []\n",
        "    all_warnings = []\n",
        "    for filename in sorted(os.listdir(pdf_dir)):\n",
        "        if not filename.lower().endswith(\".pdf\"):\n",
        "            continue\n",
        "        pdf_path = os.path.join(pdf_dir, filename)\n",
        "        exam_type, year = get_exam_metadata(filename)\n",
        "        try:\n",
        "            questions, warnings = process_pdf(pdf_path, start_page=start_page)\n",
        "            all_questions.extend(questions)\n",
        "            file_warnings = [{\"file\": filename, \"warning\": w} for w in warnings]\n",
        "            all_warnings.extend(file_warnings)\n",
        "            print(f\"Extracted {len(questions)} questions from {filename} ({exam_type} {year})\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error processing {filename}: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            all_warnings.append({\"file\": filename, \"warning\": error_msg})\n",
        "\n",
        "    # Group by exam type and year and export\n",
        "    grouped_questions = {}\n",
        "    for q in all_questions:\n",
        "        id_parts = q['id'].split('-')\n",
        "        if len(id_parts) >= 2:\n",
        "            exam_type, year = id_parts[0], id_parts[1]\n",
        "            key = f\"{exam_type}-{year}\"\n",
        "            if key not in grouped_questions:\n",
        "                grouped_questions[key] = []\n",
        "            grouped_questions[key].append(q)\n",
        "\n",
        "    for key, questions in grouped_questions.items():\n",
        "        exam_type, year = key.split('-')\n",
        "        json_path, csv_path = export_questions(\n",
        "            questions,\n",
        "            output_dir,\n",
        "            exam_type=exam_type,\n",
        "            year=year\n",
        "        )\n",
        "        if json_path:\n",
        "            print(f\"Exported {len(questions)} {exam_type} {year} questions to:\")\n",
        "            print(f\"  - JSON: {os.path.basename(json_path)}\")\n",
        "            print(f\"  - CSV: {os.path.basename(csv_path)}\")\n",
        "\n",
        "    if all_warnings:\n",
        "        warnings_df = pd.DataFrame(all_warnings)\n",
        "        warnings_path = os.path.join(output_dir, \"extraction_warnings.csv\")\n",
        "        warnings_df.to_csv(warnings_path, index=False)\n",
        "        print(f\"Exported {len(all_warnings)} warnings to {warnings_path}\")\n",
        "\n",
        "# Then call the function:\n",
        "process_directory(PDF_DIR, OUTPUT_DIR, start_page=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3ucL50aSkOq",
        "outputId": "f4c7ef56-5957-4490-8ec0-e6edb1a93cf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping question with number 1 (min valid is 26) on page 3.\n",
            "Skipping question with number 2 (min valid is 26) on page 3.\n",
            "Skipping question with number 3 (min valid is 26) on page 3.\n",
            "Skipping question with number 4 (min valid is 26) on page 3.\n",
            "Skipping question with number 5 (min valid is 26) on page 3.\n",
            "Skipping question with number 6 (min valid is 26) on page 3.\n",
            "Skipping question with number 7 (min valid is 26) on page 4.\n",
            "Skipping question with number 8 (min valid is 26) on page 4.\n",
            "Skipping question with number 9 (min valid is 26) on page 4.\n",
            "Skipping question with number 10 (min valid is 26) on page 4.\n",
            "Skipping question with number 11 (min valid is 26) on page 4.\n",
            "Skipping question with number 12 (min valid is 26) on page 4.\n",
            "Skipping question with number 13 (min valid is 26) on page 5.\n",
            "Skipping question with number 14 (min valid is 26) on page 5.\n",
            "Skipping question with number 15 (min valid is 26) on page 5.\n",
            "Skipping question with number 16 (min valid is 26) on page 5.\n",
            "Skipping question with number 17 (min valid is 26) on page 6.\n",
            "Skipping question with number 18 (min valid is 26) on page 6.\n",
            "Skipping question with number 19 (min valid is 26) on page 6.\n",
            "Skipping question with number 20 (min valid is 26) on page 6.\n",
            "Skipping question with number 21 (min valid is 26) on page 6.\n",
            "Skipping question with number 22 (min valid is 26) on page 6.\n",
            "Skipping question with number 23 (min valid is 26) on page 7.\n",
            "Skipping question with number 24 (min valid is 26) on page 7.\n",
            "Skipping question with number 25 (min valid is 26) on page 7.\n",
            "WARNING: Expected question number 26 but found 31 on page 8.\n",
            "Skipping question with number 4 (min valid is 26) on page 8.\n",
            "WARNING: Expected question number 26 but found 38 on page 9.\n",
            "Skipping question with number 3 (min valid is 26) on page 9.\n",
            "WARNING: Expected question number 42 but found 43 on page 9.\n",
            "WARNING: Expected question number 26 but found 45 on page 10.\n",
            "Skipping question with number 4 (min valid is 26) on page 10.\n",
            "WARNING: Expected question number 46 but found 47 on page 10.\n",
            "Skipping question with number 4 (min valid is 26) on page 10.\n",
            "WARNING: Expected question number 50 but found 51 on page 10.\n",
            "WARNING: Expected question number 26 but found 53 on page 11.\n",
            "WARNING: Expected question number 26 but found 57 on page 12.\n",
            "Skipping question with number 2 (min valid is 26) on page 12.\n",
            "WARNING: Expected question number 61 but found 62 on page 12.\n",
            "WARNING: Expected question number 26 but found 64 on page 13.\n",
            "WARNING: Expected question number 26 but found 69 on page 14.\n",
            "WARNING: Expected question number 26 but found 78 on page 15.\n",
            "WARNING: Expected question number 26 but found 84 on page 16.\n",
            "Skipping question with number 5 (min valid is 26) on page 16.\n",
            "WARNING: Expected question number 26 but found 91 on page 17.\n",
            "WARNING: Expected question number 26 but found 99 on page 18.\n",
            "WARNING: Expected question number 26 but found 106 on page 19.\n",
            "WARNING: Expected question number 26 but found 114 on page 20.\n",
            "WARNING: Expected question number 26 but found 122 on page 21.\n",
            "WARNING: Expected question number 26 but found 128 on page 22.\n",
            "WARNING: Expected question number 26 but found 133 on page 23.\n",
            "WARNING: Expected question number 26 but found 137 on page 24.\n",
            "Skipping question with number 3 (min valid is 26) on page 24.\n",
            "Skipping question with number 3 (min valid is 26) on page 24.\n",
            "WARNING: Expected question number 26 but found 144 on page 25.\n",
            "WARNING: Expected question number 26 but found 151 on page 26.\n",
            "Skipping question with number 2 (min valid is 26) on page 26.\n",
            "WARNING: Expected question number 153 but found 154 on page 26.\n",
            "WARNING: Expected question number 26 but found 158 on page 27.\n",
            "WARNING: Expected question number 26 but found 164 on page 28.\n",
            "WARNING: Expected question number 26 but found 169 on page 29.\n",
            "Skipping question with number 4 (min valid is 26) on page 29.\n",
            "WARNING: Expected question number 170 but found 172 on page 29.\n",
            "WARNING: Expected question number 26 but found 174 on page 30.\n",
            "WARNING: Expected question number 26 but found 179 on page 31.\n",
            "WARNING: Expected question number 26 but found 185 on page 32.\n",
            "WARNING: Expected question number 26 but found 191 on page 33.\n",
            "WARNING: Expected question number 26 but found 197 on page 34.\n",
            "Skipping question with number 23 (min valid is 26) on page 34.\n",
            "WARNING: Expected question number 200 but found 201 on page 34.\n",
            "WARNING: Expected question number 26 but found 203 on page 35.\n",
            "Skipping question with number 3 (min valid is 26) on page 35.\n",
            "WARNING: Expected question number 206 but found 207 on page 35.\n",
            "WARNING: Expected question number 210 but found 53 on page 35.\n",
            "Extraction completed successfully: 171 questions extracted.\n",
            "Extracted 171 questions from Cuaderno_2024_MEDICINA_0_C.pdf (MIR 2024)\n",
            "Exported 171 MIR 2024 questions to:\n",
            "  - JSON: MIR-2024-v01-t01.json\n",
            "  - CSV: MIR-2024-v01-t01.csv\n"
          ]
        }
      ]
    }
  ]
}