{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOH8XzWardWCGDhKrV1icbV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armelida/MELIDA/blob/main/notebooks/prompting_strategy_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Check Runtime & GPU Availability\n",
        "import torch\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def check_runtime():\n",
        "    \"\"\"Check whether a GPU or TPU is available.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"✅ GPU is enabled! Using: {gpu_name}\")\n",
        "    elif \"COLAB_TPU_ADDR\" in os.environ:\n",
        "        print(\"✅ TPU is enabled!\")\n",
        "    else:\n",
        "        print(\"⚠️ WARNING: No GPU or TPU detected. Running on CPU.\")\n",
        "        print(\"👉 Go to Runtime > Change runtime type > Select GPU/TPU\")\n",
        "\n",
        "def check_gpu():\n",
        "    \"\"\"Check GPU details using nvidia-smi if available.\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            print(\"⚠️ `nvidia-smi` not found. No GPU detected.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ No GPU found.\")\n",
        "\n",
        "# Run the checks\n",
        "check_runtime()\n",
        "check_gpu()\n"
      ],
      "metadata": {
        "id": "CG1EFB_YxqIN",
        "outputId": "f399660e-5279-453d-c1e7-f5d70e6cc49c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU is enabled! Using: NVIDIA A100-SXM4-40GB\n",
            "Mon Mar 17 21:33:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             42W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone Repository & Install Requirements\n",
        "# Remove any existing directory and clone a fresh copy of MELIDA.\n",
        "!rm -rf MELIDA\n",
        "!git clone https://github.com/armelida/MELIDA.git\n",
        "%cd MELIDA\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "ka1cnxo8xuD2",
        "outputId": "1a7f2663-1e9f-4795-f58e-88428a13183c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MELIDA'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 188 (delta 90), reused 48 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (188/188), 168.39 KiB | 8.02 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/MELIDA\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.61.1)\n",
            "Collecting anthropic>=0.7.0 (from -r requirements.txt (line 2))\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Collecting jupyter>=1.0.0 (from -r requirements.txt (line 7))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.18.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.3.6)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, json5, jedi, fqdn, async-lru, jupyter-server-terminals, jupyter-client, arrow, isoduration, anthropic, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "Successfully installed anthropic-0.49.0 arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Setup Configuration & Fetch Prompt Strategies\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Create config directory if it does not exist\n",
        "os.makedirs('config', exist_ok=True)\n",
        "\n",
        "def fetch_prompt_strategies(url):\n",
        "    \"\"\"Fetch prompt strategies JSON from GitHub and add extra metadata.\"\"\"\n",
        "    print(f\"Fetching prompt strategies from GitHub: {url}\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        strategies = response.json()\n",
        "        print(f\"✓ Loaded {len(strategies)} prompt strategies.\")\n",
        "\n",
        "        # Enrich each strategy with language and tags if missing\n",
        "        for strategy in strategies.values():\n",
        "            if \"language\" not in strategy:\n",
        "                desc = strategy.get(\"description\", \"\")\n",
        "                if \"Spanish\" in desc:\n",
        "                    strategy[\"language\"] = \"Spanish\"\n",
        "                elif \"English\" in desc:\n",
        "                    strategy[\"language\"] = \"English\"\n",
        "                else:\n",
        "                    strategy[\"language\"] = \"Unknown\"\n",
        "            if \"tags\" not in strategy:\n",
        "                strategy[\"tags\"] = []\n",
        "                if \"doctor\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"doctor_role\")\n",
        "                if \"reasoning\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"reasoning\")\n",
        "                if \"confidence\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"confidence\")\n",
        "        return strategies\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\\nUsing default prompt strategies instead.\")\n",
        "        # Default prompt strategies as fallback\n",
        "        return {\n",
        "            \"Prompt-001\": {\n",
        "                \"description\": \"Basic prompt for test-taking\",\n",
        "                \"template\": (\"Answer the following question:\\n\\n{question_text}\\n\\n\"\n",
        "                             \"A) {option_a}\\nB) {option_b}\\nC) {option_c}\\nD) {option_d}\\n\\n\"\n",
        "                             \"Your answer (only A, B, C, D):\")\n",
        "            }\n",
        "        }\n",
        "\n",
        "github_url = \"https://raw.githubusercontent.com/armelida/MELIDA/main/config/prompt_strategies.json\"\n",
        "prompt_strategies = fetch_prompt_strategies(github_url)\n",
        "\n",
        "# Validate required placeholders in each strategy\n",
        "required_placeholders = [\"{question_text}\", \"{option_a}\", \"{option_b}\", \"{option_c}\", \"{option_d}\"]\n",
        "for sid, strategy in prompt_strategies.items():\n",
        "    template = strategy.get(\"template\", \"\")\n",
        "    missing = [ph for ph in required_placeholders if ph not in template]\n",
        "    if missing:\n",
        "        print(f\"Warning: Strategy {sid} is missing placeholders: {', '.join(missing)}\")\n",
        "\n",
        "# Save the strategies locally\n",
        "with open('config/prompt_strategies.json', 'w') as f:\n",
        "    json.dump(prompt_strategies, f, indent=2)\n",
        "print(\"✓ Prompt strategies saved to config/prompt_strategies.json\")\n"
      ],
      "metadata": {
        "id": "RG2rkM_Nx-mz",
        "outputId": "6ae81312-1696-4f7f-ff65-1ee88dd085a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching prompt strategies from GitHub: https://raw.githubusercontent.com/armelida/MELIDA/main/config/prompt_strategies.json\n",
            "✓ Loaded 5 prompt strategies.\n",
            "✓ Prompt strategies saved to config/prompt_strategies.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load API Keys & Save API Configuration\n",
        "!pip install python-dotenv\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "!pip install python-dotenv\n",
        "\n",
        "# Initialize API keys dictionary\n",
        "api_keys = {\"openai\": None, \"anthropic\": None}\n",
        "\n",
        "# Try to load from Colab secrets (if available)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_keys[\"openai\"] = userdata.get('OPENAI_API_KEY')\n",
        "    api_keys[\"anthropic\"] = userdata.get('ANTHROPIC_API_KEY')\n",
        "    if api_keys[\"openai\"] and api_keys[\"anthropic\"]:\n",
        "        print(\"✓ API keys loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Couldn't load from Colab secrets - {e}\")\n",
        "\n",
        "# Fallback: load from environment variables\n",
        "if not all(api_keys.values()):\n",
        "    api_keys[\"openai\"] = api_keys[\"openai\"] or os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_keys[\"anthropic\"] = api_keys[\"anthropic\"] or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    if api_keys[\"openai\"] or api_keys[\"anthropic\"]:\n",
        "        print(\"✓ API keys loaded from environment variables\")\n",
        "\n",
        "# Fallback: load from a .env file\n",
        "if not all(api_keys.values()):\n",
        "    try:\n",
        "        load_dotenv()\n",
        "        api_keys[\"openai\"] = api_keys[\"openai\"] or os.environ.get(\"OPENAI_API_KEY\")\n",
        "        api_keys[\"anthropic\"] = api_keys[\"anthropic\"] or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        if api_keys[\"openai\"] or api_keys[\"anthropic\"]:\n",
        "            print(\"✓ API keys loaded from .env file\")\n",
        "    except Exception as e:\n",
        "        print(f\"Note: Couldn't load from .env file - {e}\")\n",
        "\n",
        "# Propagate keys to os.environ so subsequent cells can access them\n",
        "if api_keys[\"openai\"]:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_keys[\"openai\"]\n",
        "if api_keys[\"anthropic\"]:\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = api_keys[\"anthropic\"]\n",
        "\n",
        "# Create and save API configuration\n",
        "api_config = {\n",
        "    \"openai\": {\"api_key\": api_keys[\"openai\"] or \"YOUR_OPENAI_API_KEY_HERE\"},\n",
        "    \"anthropic\": {\"api_key\": api_keys[\"anthropic\"] or \"YOUR_ANTHROPIC_API_KEY_HERE\"}\n",
        "}\n",
        "with open('config/api_config.json', 'w') as f:\n",
        "    json.dump(api_config, f, indent=2)\n",
        "\n",
        "if api_keys[\"openai\"] and api_keys[\"anthropic\"]:\n",
        "    print(\"✓ Complete API configuration saved\")\n",
        "else:\n",
        "    missing = []\n",
        "    if not api_keys[\"openai\"]:\n",
        "        missing.append(\"OpenAI\")\n",
        "    if not api_keys[\"anthropic\"]:\n",
        "        missing.append(\"Anthropic\")\n",
        "    print(f\"⚠ Missing API keys: {', '.join(missing)}\")\n",
        "    print(\"Please set the API keys using one of the available methods.\")\n"
      ],
      "metadata": {
        "id": "SEKJcEW_yDoh",
        "outputId": "e6d5a726-991e-48be-a7d1-c55f9caabd3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "✓ API keys loaded from Colab secrets\n",
            "✓ Complete API configuration saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Data Loading & Standardization (Updated)\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"\\n--- Data Loading ---\")\n",
        "questions_file = 'data/questions/MIR-2024-v01-t01.json'\n",
        "answers_file = 'data/answers/MIR-2024-v01-t01-answers.json'\n",
        "\n",
        "# Ensure the questions directory exists (it should, but just in case)\n",
        "os.makedirs(os.path.dirname(questions_file), exist_ok=True)\n",
        "\n",
        "# Load questions\n",
        "with open(questions_file, 'r', encoding='utf-8') as f:\n",
        "    questions = json.load(f)\n",
        "print(f\"✓ Loaded {len(questions)} questions from {questions_file}\")\n",
        "\n",
        "# Convert the list of questions to a dictionary keyed by question ID if needed\n",
        "if isinstance(questions, list):\n",
        "    questions = {q['id']: q for q in questions}\n",
        "    print(\"✓ Converted questions list to a dictionary keyed by question ID\")\n",
        "\n",
        "    # Save the converted questions back to disk in the same folder\n",
        "    dict_questions_file = 'data/questions/MIR-2024-v01-t01-dict.json'\n",
        "    with open(dict_questions_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(questions, f, indent=2)\n",
        "    print(f\"✓ Saved converted questions to {dict_questions_file}\")\n",
        "\n",
        "# Load answers (assumed as a dictionary)\n",
        "with open(answers_file, 'r', encoding='utf-8') as f:\n",
        "    answers_dict = json.load(f)\n",
        "print(f\"✓ Loaded answers from {answers_file}\")\n",
        "\n",
        "# Convert answers dictionary to list format for the evaluator\n",
        "answers = [{\"id\": qid, \"correct_option\": ans} for qid, ans in answers_dict.items()]\n",
        "print(f\"✓ Converted answers to list format with {len(answers)} items\")\n",
        "\n",
        "# Save standardized answers for the evaluator\n",
        "std_answers_file = 'data/answers/MIR-2024-v01-t01-answers-standardized.json'\n",
        "with open(std_answers_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(answers, f, indent=2)\n",
        "print(f\"✓ Standardized answers saved to {std_answers_file}\")\n",
        "\n",
        "# Check for matching question IDs and answer IDs\n",
        "question_ids = set(questions.keys())\n",
        "answer_ids = {a['id'] for a in answers}\n",
        "matched = question_ids.intersection(answer_ids)\n",
        "print(f\"✓ Found {len(matched)} matching questions out of {len(question_ids)} total questions\")\n"
      ],
      "metadata": {
        "id": "i2UZgLugx64r",
        "outputId": "a5aac624-ad30-4407-ad7f-fa5212790c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Loading ---\n",
            "✓ Loaded 174 questions from data/questions/MIR-2024-v01-t01.json\n",
            "✓ Converted questions list to a dictionary keyed by question ID\n",
            "✓ Saved converted questions to data/questions/MIR-2024-v01-t01-dict.json\n",
            "✓ Loaded answers from data/answers/MIR-2024-v01-t01-answers.json\n",
            "✓ Converted answers to list format with 174 items\n",
            "✓ Standardized answers saved to data/answers/MIR-2024-v01-t01-answers-standardized.json\n",
            "✓ Found 174 matching questions out of 174 total questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Run Sample Evaluation (5 Questions per Model)\n",
        "import json\n",
        "from src.evaluator import ModelEvaluator\n",
        "\n",
        "\n",
        "# Define parameters:\n",
        "# Using two models: gpt-4o-mini (OpenAI) and claude-3.7-Sonnet (Claude)\n",
        "models_to_test = ['o3-mini', 'claude-3-7-sonnet-20250219']\n",
        "# Using 10 prompting strategies (we'll use the first for sample evaluation)\n",
        "prompt_strategies_to_test = [f'Prompt-{i:03d}' for i in range(1, 11)]\n",
        "\n",
        "sample_size = 5  # Test 5 questions per model\n",
        "\n",
        "# Use the original questions file (list format) and answer key file (dictionary)\n",
        "questions_file = 'data/questions/MIR-2024-v01-t01.json'\n",
        "answer_key_file = 'data/answers/MIR-2024-v01-t01-answers.json'\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEvaluator()\n",
        "\n",
        "print(\"\\n--- RUNNING SAMPLE EVALUATION ---\")\n",
        "results_summary = {}\n",
        "\n",
        "# Loop through each model and run a sample evaluation with sample_size = 5\n",
        "for model in models_to_test:\n",
        "    # For sample testing, we'll use the first prompt strategy (Prompt-001)\n",
        "    prompt_strategy = prompt_strategies_to_test[0]\n",
        "    print(f\"\\nEvaluating Model: {model} using Prompt Strategy: {prompt_strategy}\")\n",
        "    try:\n",
        "        result_file = evaluator.run_evaluation(\n",
        "            questions_file=questions_file,\n",
        "            answer_key_file=answer_key_file,\n",
        "            prompt_strategy=prompt_strategy,\n",
        "            model=model,\n",
        "            sample_size=sample_size\n",
        "        )\n",
        "        print(f\"✓ Sample evaluation complete for {model}. Results saved to: {result_file}\")\n",
        "\n",
        "        # Load and display the summary of the evaluation results\n",
        "        with open(result_file, 'r') as f:\n",
        "            results = json.load(f)\n",
        "        summary = results.get('summary', {})\n",
        "        results_summary[model] = summary\n",
        "\n",
        "        print(\"\\n--- SAMPLE EVALUATION RESULTS ---\")\n",
        "        print(f\"Model: {summary.get('model', 'N/A')}\")\n",
        "        print(f\"Prompt Strategy: {summary.get('prompt_strategy', 'N/A')}\")\n",
        "        print(f\"Total Questions: {summary.get('total_questions', 'N/A')}\")\n",
        "        print(f\"Correct Answers: {summary.get('correct_count', 'N/A')} ({summary.get('accuracy', 0)*100:.2f}%)\")\n",
        "        print(f\"Incorrect Answers: {summary.get('incorrect_count', 'N/A')}\")\n",
        "        print(f\"Skipped Questions: {summary.get('skipped_count', 'N/A')}\")\n",
        "        print(f\"Unknown/No clear answer: {summary.get('unknown_count', 'N/A')}\")\n",
        "        print(f\"Total Score: {summary.get('total_score', 'N/A')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error during sample evaluation for {model}: {e}\")\n",
        "\n",
        "print(\"\\nIf the sample evaluation looks good, proceed to full evaluation in the next cell.\")\n"
      ],
      "metadata": {
        "id": "3medg8EOx4S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b309a5-416c-42ed-9091-45543d4757f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING SAMPLE EVALUATION ---\n",
            "\n",
            "Evaluating Model: o3-mini using Prompt Strategy: Prompt-001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating questions: 100%|██████████| 5/5 [00:09<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Sample evaluation complete for o3-mini. Results saved to: data/results/EVAL-MIR-2024-v01-t01-Prompt-001-o3-mini-20250317-213527.json\n",
            "\n",
            "--- SAMPLE EVALUATION RESULTS ---\n",
            "Model: o3-mini\n",
            "Prompt Strategy: Prompt-001\n",
            "Total Questions: 5\n",
            "Correct Answers: 0 (0.00%)\n",
            "Incorrect Answers: 0\n",
            "Skipped Questions: 0\n",
            "Unknown/No clear answer: N/A\n",
            "Total Score: 0\n",
            "\n",
            "Evaluating Model: claude-3-7-sonnet-20250219 using Prompt Strategy: Prompt-001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating questions: 100%|██████████| 5/5 [00:09<00:00,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Sample evaluation complete for claude-3-7-sonnet-20250219. Results saved to: data/results/EVAL-MIR-2024-v01-t01-Prompt-001-claude-3-7-sonnet-20250219-20250317-213537.json\n",
            "\n",
            "--- SAMPLE EVALUATION RESULTS ---\n",
            "Model: claude-3-7-sonnet-20250219\n",
            "Prompt Strategy: Prompt-001\n",
            "Total Questions: 5\n",
            "Correct Answers: 4 (80.00%)\n",
            "Incorrect Answers: 1\n",
            "Skipped Questions: 0\n",
            "Unknown/No clear answer: N/A\n",
            "Total Score: 11\n",
            "\n",
            "If the sample evaluation looks good, proceed to full evaluation in the next cell.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Run Full Evaluation\n",
        "import os\n",
        "import json\n",
        "from src.evaluator import ModelEvaluator\n",
        "\n",
        "# Define parameters:\n",
        "models_to_test = ['gpt-4o-mini', 'claude-3-7-sonnet-20250219']\n",
        "prompt_strategies_to_test = [f'Prompt-{i:03d}' for i in range(1, 11)]\n",
        "\n",
        "# Use the original questions file and answer key file (as expected by the evaluator)\n",
        "questions_file = 'data/questions/MIR-2024-v01-t01.json'\n",
        "answer_key_file = 'data/answers/MIR-2024-v01-t01-answers.json'\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEvaluator()\n",
        "\n",
        "result_files = []\n",
        "\n",
        "print(\"\\n--- RUNNING FULL EVALUATION ---\")\n",
        "for model in models_to_test:\n",
        "    for prompt_strategy in prompt_strategies_to_test:\n",
        "        print(f\"\\nEvaluating Model: {model} | Prompt Strategy: {prompt_strategy}\")\n",
        "        try:\n",
        "            result_file = evaluator.run_evaluation(\n",
        "                questions_file=questions_file,\n",
        "                answer_key_file=answer_key_file,\n",
        "                prompt_strategy=prompt_strategy,\n",
        "                model=model,\n",
        "                sample_size=None  # Use all questions\n",
        "            )\n",
        "            result_files.append(result_file)\n",
        "            print(f\"✓ Evaluation complete. Results saved to: {result_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error during evaluation for Model: {model} | Prompt: {prompt_strategy} --> {e}\")\n",
        "\n",
        "print(f\"\\n--- FULL EVALUATION COMPLETE ---\")\n",
        "print(f\"Generated {len(result_files)} result files\")\n",
        "\n",
        "# Optionally, list out the generated result files\n",
        "for rf in result_files:\n",
        "    print(rf)\n"
      ],
      "metadata": {
        "id": "rUwahXLJx2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Analyze Results & Export Data for Tableau\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "def merge_results(result_files):\n",
        "    \"\"\"Merge evaluation summaries and details from all result files.\"\"\"\n",
        "    all_summaries = []\n",
        "    all_details = []\n",
        "\n",
        "    for file in result_files:\n",
        "        try:\n",
        "            with open(file, 'r') as f:\n",
        "                results = json.load(f)\n",
        "            # Append the summary (if available) and details from each evaluation\n",
        "            all_summaries.append(results.get('summary', {}))\n",
        "            all_details.extend(results.get('results', []))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "    return all_summaries, all_details\n",
        "\n",
        "# If result_files is not available from Cell 7, search the results folder\n",
        "if 'result_files' not in globals() or not result_files:\n",
        "    result_dir = \"data/results\"\n",
        "    result_files = [os.path.join(result_dir, f) for f in os.listdir(result_dir) if f.endswith(\"_results.json\")]\n",
        "    print(f\"Found {len(result_files)} result files in {result_dir}\")\n",
        "\n",
        "# Merge the results from all evaluations\n",
        "summaries, details = merge_results(result_files)\n",
        "\n",
        "# Create pandas DataFrames for summaries and details\n",
        "summary_df = pd.DataFrame(summaries)\n",
        "details_df = pd.DataFrame(details)\n",
        "\n",
        "# Prepare export directory and filenames with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "export_dir = \"data/exports\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "summary_csv = os.path.join(export_dir, f\"evaluation_summary_{timestamp}.csv\")\n",
        "details_csv = os.path.join(export_dir, f\"evaluation_details_{timestamp}.csv\")\n",
        "\n",
        "# Export the dataframes to CSV for Tableau\n",
        "summary_df.to_csv(summary_csv, index=False)\n",
        "details_df.to_csv(details_csv, index=False)\n",
        "print(f\"✓ Exported evaluation summary to: {summary_csv}\")\n",
        "print(f\"✓ Exported evaluation details to: {details_csv}\")\n",
        "\n",
        "# Create visualizations for model performance\n",
        "\n",
        "# Visualization: Model Accuracy by Prompt Strategy\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(x='model', y='accuracy', hue='prompt_strategy', data=summary_df)\n",
        "plt.title('Model Accuracy by Prompt Strategy', fontsize=16)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(title='Prompt Strategy', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "accuracy_plot_path = os.path.join(export_dir, f\"accuracy_comparison_{timestamp}.png\")\n",
        "plt.savefig(accuracy_plot_path, dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Visualization: Total Score by Model and Prompt Strategy\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(x='model', y='total_score', hue='prompt_strategy', data=summary_df)\n",
        "plt.title('Total Score by Model and Prompt Strategy', fontsize=16)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Prompt Strategy', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "score_plot_path = os.path.join(export_dir, f\"score_comparison_{timestamp}.png\")\n",
        "plt.savefig(score_plot_path, dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Display best performing combinations (top 5)\n",
        "print(\"\\n--- BEST PERFORMING COMBINATIONS ---\")\n",
        "summary_df['formatted_accuracy'] = summary_df['accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "best_combos = summary_df.sort_values('accuracy', ascending=False)[['model', 'prompt_strategy', 'formatted_accuracy', 'total_score']].head(5)\n",
        "print(best_combos)\n"
      ],
      "metadata": {
        "id": "fJF9BQcgxqL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lo-IMi7yxqRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Troubleshooting*"
      ],
      "metadata": {
        "id": "uPxn7bkDDb7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"your_api_key_here\"\n",
        "prompt = \"Answer the following question:\\n\\nWhat is 2+2?\\n\\nA) 3\\nB) 4\\nC) 5\\nD) 6\\n\\nYour answer (ONLY A, B, C, D, or NO if uncertain):\"\n",
        "try:\n",
        "    response = openai.OpenAI(api_key=openai.api_key).chat.completions.create(\n",
        "        model=\"o3-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=10\n",
        "    )\n",
        "    print(\"Raw API response:\", response)\n",
        "    print(\"Extracted content:\", response.choices[0].message.content.strip())\n",
        "except Exception as e:\n",
        "    print(\"Error during test API call:\", e)\n"
      ],
      "metadata": {
        "id": "-FoRm7NMxqT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075d90bb-5016-4d08-8e9a-95132b23f365"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during test API call: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_api*****here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrrbE5DSxqWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTtofFuXxqZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNMqQ0qDxqdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVCMgt0zxqfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsQDSlTCxqjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHPnUxD0xqnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlQyG16Rxqp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7lkFbtLxqtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdxxN3lpxqvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ujrgwl15xqzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAwQi2cZxq3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtoO61GDxq6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lrAB4W9xq94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3QOLgmExrB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}