{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNmlYXDe/N+hHCPg8Hw4JMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armelida/MELIDA/blob/main/notebooks/prompting_strategy_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MELIDA: Model Evaluation for Life-sciences Intelligence and Decision Assistance\n",
        "# Simplified Notebook for Running Evaluations\n",
        "\n",
        "# Cell 1: Check Runtime & GPU Availability\n",
        "import torch\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def check_runtime():\n",
        "    \"\"\"Check whether a GPU or TPU is available.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"‚úÖ GPU is enabled! Using: {gpu_name}\")\n",
        "    elif \"COLAB_TPU_ADDR\" in os.environ:\n",
        "        print(\"‚úÖ TPU is enabled!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è WARNING: No GPU or TPU detected. Running on CPU.\")\n",
        "        print(\"üëâ Go to Runtime > Change runtime type > Select GPU/TPU\")\n",
        "\n",
        "def check_gpu():\n",
        "    \"\"\"Check GPU details using nvidia-smi if available.\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è `nvidia-smi` not found. No GPU detected.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è No GPU found.\")\n",
        "\n",
        "# Run the checks\n",
        "check_runtime()\n",
        "check_gpu()\n"
      ],
      "metadata": {
        "id": "CG1EFB_YxqIN",
        "outputId": "3b24cf0c-1946-489a-f000-8ba5a335bd31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU is enabled! Using: NVIDIA A100-SXM4-40GB\n",
            "Sun Mar 16 11:52:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             43W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone Repository & Install Requirements\n",
        "# Remove any existing directory and clone a fresh copy of MELIDA.\n",
        "!rm -rf MELIDA\n",
        "!git clone https://github.com/armelida/MELIDA.git\n",
        "%cd MELIDA\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "ka1cnxo8xuD2",
        "outputId": "07de70c6-2ea0-48ee-b054-1618f5db44ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MELIDA'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 148 (delta 65), reused 49 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (148/148), 148.84 KiB | 2.01 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/MELIDA\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.61.1)\n",
            "Requirement already satisfied: anthropic>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.49.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 7)) (4.3.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.0.4)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.3.6)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.23.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (24.11.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 7)) (2.9.0.20241206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Setup Configuration & Fetch Prompt Strategies\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Create config directory if it does not exist\n",
        "os.makedirs('config', exist_ok=True)\n",
        "\n",
        "def fetch_prompt_strategies(url):\n",
        "    \"\"\"Fetch prompt strategies JSON from GitHub and add extra metadata.\"\"\"\n",
        "    print(f\"Fetching prompt strategies from GitHub: {url}\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        strategies = response.json()\n",
        "        print(f\"‚úì Loaded {len(strategies)} prompt strategies.\")\n",
        "\n",
        "        # Enrich each strategy with language and tags if missing\n",
        "        for strategy in strategies.values():\n",
        "            if \"language\" not in strategy:\n",
        "                desc = strategy.get(\"description\", \"\")\n",
        "                if \"Spanish\" in desc:\n",
        "                    strategy[\"language\"] = \"Spanish\"\n",
        "                elif \"English\" in desc:\n",
        "                    strategy[\"language\"] = \"English\"\n",
        "                else:\n",
        "                    strategy[\"language\"] = \"Unknown\"\n",
        "            if \"tags\" not in strategy:\n",
        "                strategy[\"tags\"] = []\n",
        "                if \"doctor\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"doctor_role\")\n",
        "                if \"reasoning\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"reasoning\")\n",
        "                if \"confidence\" in strategy.get(\"description\", \"\").lower():\n",
        "                    strategy[\"tags\"].append(\"confidence\")\n",
        "        return strategies\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\\nUsing default prompt strategies instead.\")\n",
        "        # Default prompt strategies as fallback\n",
        "        return {\n",
        "            \"Prompt-001\": {\n",
        "                \"description\": \"Basic prompt for test-taking\",\n",
        "                \"template\": (\"Answer the following question:\\n\\n{question_text}\\n\\n\"\n",
        "                             \"A) {option_a}\\nB) {option_b}\\nC) {option_c}\\nD) {option_d}\\n\\n\"\n",
        "                             \"Your answer (only A, B, C, D):\")\n",
        "            }\n",
        "        }\n",
        "\n",
        "github_url = \"https://raw.githubusercontent.com/armelida/MELIDA/main/config/prompt_strategies.json\"\n",
        "prompt_strategies = fetch_prompt_strategies(github_url)\n",
        "\n",
        "# Validate required placeholders in each strategy\n",
        "required_placeholders = [\"{question_text}\", \"{option_a}\", \"{option_b}\", \"{option_c}\", \"{option_d}\"]\n",
        "for sid, strategy in prompt_strategies.items():\n",
        "    template = strategy.get(\"template\", \"\")\n",
        "    missing = [ph for ph in required_placeholders if ph not in template]\n",
        "    if missing:\n",
        "        print(f\"Warning: Strategy {sid} is missing placeholders: {', '.join(missing)}\")\n",
        "\n",
        "# Save the strategies locally\n",
        "with open('config/prompt_strategies.json', 'w') as f:\n",
        "    json.dump(prompt_strategies, f, indent=2)\n",
        "print(\"‚úì Prompt strategies saved to config/prompt_strategies.json\")\n"
      ],
      "metadata": {
        "id": "WZWOr1ecx0Zh",
        "outputId": "580c33bf-675d-4f85-c888-9d936f022d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching prompt strategies from GitHub: https://raw.githubusercontent.com/armelida/MELIDA/main/config/prompt_strategies.json\n",
            "‚úì Loaded 10 prompt strategies.\n",
            "‚úì Prompt strategies saved to config/prompt_strategies.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load API Keys & Save API Configuration\n",
        "!pip install python-dotenv\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Initialize API keys dictionary\n",
        "api_keys = {\"openai\": None, \"anthropic\": None}\n",
        "\n",
        "# Try to load from Colab secrets (if available)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_keys[\"openai\"] = userdata.get('OPENAI_API_KEY')\n",
        "    api_keys[\"anthropic\"] = userdata.get('ANTHROPIC_API_KEY')\n",
        "    if api_keys[\"openai\"] and api_keys[\"anthropic\"]:\n",
        "        print(\"‚úì API keys loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Couldn't load from Colab secrets - {e}\")\n",
        "\n",
        "# Fallback: load from environment variables\n",
        "if not all(api_keys.values()):\n",
        "    api_keys[\"openai\"] = api_keys[\"openai\"] or os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_keys[\"anthropic\"] = api_keys[\"anthropic\"] or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    if api_keys[\"openai\"] or api_keys[\"anthropic\"]:\n",
        "        print(\"‚úì API keys loaded from environment variables\")\n",
        "\n",
        "# Fallback: load from a .env file\n",
        "if not all(api_keys.values()):\n",
        "    try:\n",
        "        load_dotenv()\n",
        "        api_keys[\"openai\"] = api_keys[\"openai\"] or os.environ.get(\"OPENAI_API_KEY\")\n",
        "        api_keys[\"anthropic\"] = api_keys[\"anthropic\"] or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        if api_keys[\"openai\"] or api_keys[\"anthropic\"]:\n",
        "            print(\"‚úì API keys loaded from .env file\")\n",
        "    except Exception as e:\n",
        "        print(f\"Note: Couldn't load from .env file - {e}\")\n",
        "\n",
        "# Create and save API configuration\n",
        "api_config = {\n",
        "    \"openai\": {\"api_key\": api_keys[\"openai\"] or \"YOUR_OPENAI_API_KEY_HERE\"},\n",
        "    \"anthropic\": {\"api_key\": api_keys[\"anthropic\"] or \"YOUR_ANTHROPIC_API_KEY_HERE\"}\n",
        "}\n",
        "with open('config/api_config.json', 'w') as f:\n",
        "    json.dump(api_config, f, indent=2)\n",
        "\n",
        "if api_keys[\"openai\"] and api_keys[\"anthropic\"]:\n",
        "    print(\"‚úì Complete API configuration saved\")\n",
        "else:\n",
        "    missing = []\n",
        "    if not api_keys[\"openai\"]:\n",
        "        missing.append(\"OpenAI\")\n",
        "    if not api_keys[\"anthropic\"]:\n",
        "        missing.append(\"Anthropic\")\n",
        "    print(f\"‚ö† Missing API keys: {', '.join(missing)}\")\n",
        "    print(\"Please set the API keys using one of the available methods.\")\n"
      ],
      "metadata": {
        "id": "RG2rkM_Nx-mz",
        "outputId": "f175d4de-7233-4d7e-e176-80c43b1df356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "‚úì API keys loaded from Colab secrets\n",
            "‚úì Complete API configuration saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Data Loading & Standardization\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"\\n--- Data Loading ---\")\n",
        "questions_file = 'data/questions/MIR-2024-v01-t01.json'\n",
        "answers_file = 'data/answers/MIR-2024-v01-t01-answers.json'\n",
        "\n",
        "# Load questions\n",
        "with open(questions_file, 'r', encoding='utf-8') as f:\n",
        "    questions = json.load(f)\n",
        "print(f\"‚úì Loaded {len(questions)} questions from {questions_file}\")\n",
        "\n",
        "# Convert the list of questions to a dictionary keyed by question ID if needed\n",
        "if isinstance(questions, list):\n",
        "    questions = {q['id']: q for q in questions}\n",
        "    print(\"‚úì Converted questions list to a dictionary keyed by question ID\")\n",
        "\n",
        "# Load answers (assumed as a dictionary)\n",
        "with open(answers_file, 'r', encoding='utf-8') as f:\n",
        "    answers_dict = json.load(f)\n",
        "print(f\"‚úì Loaded answers from {answers_file}\")\n",
        "\n",
        "# Convert answers dictionary to list format for the evaluator\n",
        "answers = [{\"id\": qid, \"correct_option\": ans} for qid, ans in answers_dict.items()]\n",
        "print(f\"‚úì Converted answers to list format with {len(answers)} items\")\n",
        "\n",
        "# Save standardized answers for the evaluator\n",
        "std_answers_file = 'data/answers/MIR-2024-v01-t01-answers-standardized.json'\n",
        "with open(std_answers_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(answers, f, indent=2)\n",
        "print(f\"‚úì Standardized answers saved to {std_answers_file}\")\n",
        "\n",
        "# Check for matching question IDs and answer IDs\n",
        "question_ids = set(questions.keys())\n",
        "answer_ids = {a['id'] for a in answers}\n",
        "matched = question_ids.intersection(answer_ids)\n",
        "print(f\"‚úì Found {len(matched)} matching questions out of {len(question_ids)} total questions\")\n"
      ],
      "metadata": {
        "id": "SEKJcEW_yDoh",
        "outputId": "4c6be7d5-c5bc-4597-d39b-29e540a5f78e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Loading ---\n",
            "‚úì Loaded 174 questions from data/questions/MIR-2024-v01-t01.json\n",
            "‚úì Converted questions list to a dictionary keyed by question ID\n",
            "‚úì Loaded answers from data/answers/MIR-2024-v01-t01-answers.json\n",
            "‚úì Converted answers to list format with 174 items\n",
            "‚úì Standardized answers saved to data/answers/MIR-2024-v01-t01-answers-standardized.json\n",
            "‚úì Found 174 matching questions out of 174 total questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Run Sample Evaluation (Updated)\n",
        "import json\n",
        "from src.evaluator import ModelEvaluator\n",
        "\n",
        "# Define parameters\n",
        "# Using only two models: update \"o3-mini\" to the supported name \"gpt-4o-mini\"\n",
        "models_to_test = ['o3-mini-2025-01-31', 'claude-3.7-Sonnet']\n",
        "\n",
        "# Using 10 prompting strategies (Prompt-001 to Prompt-010)\n",
        "prompt_strategies_to_test = [f'Prompt-{i:03d}' for i in range(1, 11)]\n",
        "\n",
        "sample_size = 5  # Use a small sample for testing\n",
        "\n",
        "# File paths (using the standardized answers file from Cell 5)\n",
        "questions_file = 'data/questions/MIR-2024-v01-t01.json'\n",
        "std_answers_file = 'data/answers/MIR-2024-v01-t01-answers-standardized.json'\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEvaluator()\n",
        "\n",
        "print(\"\\n--- RUNNING SAMPLE EVALUATION ---\")\n",
        "# Choose first model and first prompt strategy for a sample run\n",
        "sample_model = models_to_test[0]\n",
        "sample_strategy = prompt_strategies_to_test[0]\n",
        "\n",
        "try:\n",
        "    # Run a sample evaluation using the selected model and prompt strategy\n",
        "    result_file = evaluator.run_evaluation(\n",
        "        questions_file=questions_file,\n",
        "        answer_key_file=std_answers_file,\n",
        "        prompt_strategy=sample_strategy,\n",
        "        model=sample_model,\n",
        "        sample_size=sample_size\n",
        "    )\n",
        "    print(f\"‚úì Sample evaluation complete. Results saved to: {result_file}\")\n",
        "\n",
        "    # Load and display the summary of the evaluation results\n",
        "    with open(result_file, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    summary = results.get('summary', {})\n",
        "\n",
        "    print(\"\\n--- SAMPLE EVALUATION RESULTS ---\")\n",
        "    print(f\"Model: {summary.get('model', 'N/A')}\")\n",
        "    print(f\"Prompt Strategy: {summary.get('prompt_strategy', 'N/A')}\")\n",
        "    print(f\"Total Questions: {summary.get('total_questions', 'N/A')}\")\n",
        "    print(f\"Correct Answers: {summary.get('correct_count', 'N/A')} ({summary.get('accuracy', 0)*100:.2f}%)\")\n",
        "    print(f\"Incorrect Answers: {summary.get('incorrect_count', 'N/A')}\")\n",
        "    print(f\"Skipped Questions: {summary.get('skipped_count', 'N/A')}\")\n",
        "    print(f\"Unknown/No clear answer: {summary.get('unknown_count', 'N/A')}\")\n",
        "    print(f\"Total Score: {summary.get('total_score', 'N/A')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Error during sample evaluation: {e}\")\n",
        "\n",
        "print(\"\\nIf the sample evaluation looks good, proceed to full evaluation in the next cell.\")\n"
      ],
      "metadata": {
        "id": "i2UZgLugx64r",
        "outputId": "1ce472c7-aa75-405f-aa77-b9fab7e56cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING SAMPLE EVALUATION ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating questions:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úó Error during sample evaluation: Unsupported model: o3-mini-2025-01-31\n",
            "\n",
            "If the sample evaluation looks good, proceed to full evaluation in the next cell.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Analyze Results and Create Visualizations\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "def analyze_results(result_files=None):\n",
        "    \"\"\"Analyze evaluation results and create visualizations\"\"\"\n",
        "    print(\"\\n----- ANALYZING RESULTS -----\")\n",
        "\n",
        "    # Get all result files if not provided\n",
        "    if not result_files or len(result_files) == 0:\n",
        "        result_dir = \"data/results\"\n",
        "        result_files = [os.path.join(result_dir, f) for f in os.listdir(result_dir)\n",
        "                      if f.endswith(\"_results.json\")]\n",
        "        print(f\"Found {len(result_files)} result files in {result_dir}\")\n",
        "\n",
        "    if len(result_files) == 0:\n",
        "        print(\"No result files found for analysis\")\n",
        "        return\n",
        "\n",
        "    # Merge results from all files\n",
        "    all_summaries = []\n",
        "    all_details = []\n",
        "\n",
        "    for file_path in result_files:\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                results = json.load(f)\n",
        "\n",
        "            all_summaries.append(results['summary'])\n",
        "            all_details.extend(results['results'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "    # Create dataframes\n",
        "    summary_df = pd.DataFrame(all_summaries)\n",
        "    details_df = pd.DataFrame(all_details)\n",
        "\n",
        "    # Export to CSV\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    export_dir = \"data/exports\"\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "    summary_csv = os.path.join(export_dir, f\"evaluation_summary_{timestamp}.csv\")\n",
        "    details_csv = os.path.join(export_dir, f\"evaluation_details_{timestamp}.csv\")\n",
        "\n",
        "    summary_df.to_csv(summary_csv, index=False)\n",
        "    details_df.to_csv(details_csv, index=False)\n",
        "\n",
        "    print(f\"‚úì Exported evaluation summary to: {summary_csv}\")\n",
        "    print(f\"‚úì Exported evaluation details to: {details_csv}\")\n",
        "\n",
        "    # Display best performing combinations\n",
        "    print(\"\\n----- BEST PERFORMING COMBINATIONS -----\")\n",
        "    summary_df['formatted_accuracy'] = summary_df['accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "    best_combos = summary_df.sort_values('accuracy', ascending=False)[\n",
        "        ['model', 'prompt_strategy', 'formatted_accuracy', 'total_score']\n",
        "    ].head(5)\n",
        "    print(best_combos)\n",
        "\n",
        "    # Create visualizations if we have more than one result\n",
        "    if len(all_summaries) > 1:\n",
        "        # Accuracy comparison\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.barplot(x='model', y='accuracy', hue='prompt_strategy', data=summary_df)\n",
        "        plt.title('Model Accuracy by Prompt Strategy', fontsize=16)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.legend(title='Prompt Strategy', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot\n",
        "        plot_path = os.path.join(export_dir, f\"accuracy_comparison_{timestamp}.png\")\n",
        "        plt.savefig(plot_path, dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "        return summary_df, details_df\n",
        "    else:\n",
        "        print(\"Not generating visualizations with only one result file\")\n",
        "        return summary_df, details_df\n",
        "\n",
        "# Uncomment to run the analysis on result files\n",
        "\"\"\"\n",
        "summary_df, details_df = analyze_results(result_files)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "3medg8EOx4S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Run Everything in Sequence\n",
        "def run_complete_evaluation(sample_size=5, full_eval=False):\n",
        "    \"\"\"Run the complete evaluation process from start to finish\"\"\"\n",
        "    # Setup\n",
        "    prompt_strategies = setup_prompt_strategies()\n",
        "    api_keys = setup_api_keys()\n",
        "\n",
        "    # Check if we have the required API keys\n",
        "    if not api_keys[\"openai\"] or not api_keys[\"anthropic\"]:\n",
        "        print(\"‚ö†Ô∏è Missing API keys. Please add them before continuing.\")\n",
        "        return\n",
        "\n",
        "    # Prepare data\n",
        "    questions_file, answer_key_file = prepare_evaluation_data()\n",
        "\n",
        "    # Run sample evaluation\n",
        "    sample_result = run_sample_evaluation(questions_file, answer_key_file)\n",
        "\n",
        "    # Run full evaluation if requested\n",
        "    if full_eval:\n",
        "        models_to_test = [\n",
        "            'gpt-3.5-turbo',  # Faster model for testing\n",
        "            'claude-3-7-sonnet-20250219'  # Claude model\n",
        "        ]\n",
        "\n",
        "        strategies_to_test = list(prompt_strategies.keys())[:2]  # Use first two strategies\n",
        "\n",
        "        result_files = run_full_evaluation(\n",
        "            questions_file,\n",
        "            answer_key_file,\n",
        "            models=models_to_test,\n",
        "            strategies=strategies_to_test,\n",
        "            sample_size=sample_size\n",
        "        )\n",
        "\n",
        "        # Analyze results\n",
        "        if result_files:\n",
        "            summary_df, details_df = analyze_results(result_files)\n",
        "            return summary_df, details_df\n",
        "\n",
        "    print(\"\\nEvaluation complete!\")\n",
        "\n",
        "# Uncomment to run the complete process\n",
        "\"\"\"\n",
        "# For a quick test run:\n",
        "run_complete_evaluation(sample_size=5, full_eval=False)\n",
        "\n",
        "# For a more comprehensive evaluation:\n",
        "# run_complete_evaluation(sample_size=20, full_eval=True)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rUwahXLJx2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJF9BQcgxqL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lo-IMi7yxqRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-FoRm7NMxqT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrrbE5DSxqWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTtofFuXxqZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNMqQ0qDxqdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVCMgt0zxqfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsQDSlTCxqjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHPnUxD0xqnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlQyG16Rxqp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7lkFbtLxqtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdxxN3lpxqvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ujrgwl15xqzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAwQi2cZxq3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtoO61GDxq6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lrAB4W9xq94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3QOLgmExrB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}